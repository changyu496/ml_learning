# 📐 向量相似度深度解析

## 🎯 核心概念

> **向量相似度是衡量两个向量接近程度的重要指标，是推荐系统、信息检索和自然语言处理的基础**

### 什么是向量相似度？
**定义**：向量相似度是用来衡量两个向量在方向、大小或模式上相似程度的数值指标。

**核心思想**：通过数学计算量化两个向量的相似性，数值越高表示越相似。

**应用场景**：推荐系统、搜索引擎、聚类分析、图像识别等。

---

## 🧠 几何直觉理解

### 向量的几何表示
```python
import numpy as np
import matplotlib.pyplot as plt

def vector_geometry_basics():
    """理解向量的几何表示"""
    
    # 定义几个二维向量
    v1 = np.array([3, 4])
    v2 = np.array([4, 3])
    v3 = np.array([6, 8])
    v4 = np.array([-2, 1])
    
    vectors = [v1, v2, v3, v4]
    labels = ['v1', 'v2', 'v3', 'v4']
    
    print("向量的几何表示")
    print("=" * 30)
    
    for i, (v, label) in enumerate(zip(vectors, labels)):
        # 向量长度
        length = np.linalg.norm(v)
        
        # 向量方向（单位向量）
        direction = v / length
        
        # 与x轴的角度
        angle = np.arctan2(v[1], v[0])
        angle_degrees = np.degrees(angle)
        
        print(f"{label} = {v}")
        print(f"  长度: {length:.3f}")
        print(f"  方向: {direction}")
        print(f"  角度: {angle_degrees:.1f}°")
        print()
    
    # 向量间的关系
    print("向量间的关系分析:")
    print("-" * 20)
    
    # v1 和 v3 的关系
    print(f"v1 = {v1}, v3 = {v3}")
    print(f"v3 是否为 v1 的倍数: {np.allclose(v3, 2 * v1)}")
    print(f"它们方向相同，但长度不同")
    
    # v1 和 v2 的关系
    print(f"\nv1 = {v1}, v2 = {v2}")
    print(f"它们长度相近但方向不同")
    
    # v1 和 v4 的关系
    print(f"\nv1 = {v1}, v4 = {v4}")
    print(f"它们既不平行也不垂直")
    
    return vectors

vectors = vector_geometry_basics()
```

---

## 📏 主要相似度度量方法

### 1. 欧氏距离 (Euclidean Distance)
```python
def euclidean_distance_analysis():
    """欧氏距离详解"""
    
    print("欧氏距离 (Euclidean Distance)")
    print("=" * 50)
    
    # 定义向量
    v1 = np.array([1, 2, 3])
    v2 = np.array([4, 5, 6])
    v3 = np.array([1, 2, 4])
    
    # 手工计算欧氏距离
    def euclidean_distance(a, b):
        return np.sqrt(np.sum((a - b) ** 2))
    
    # 计算距离
    dist_12 = euclidean_distance(v1, v2)
    dist_13 = euclidean_distance(v1, v3)
    dist_23 = euclidean_distance(v2, v3)
    
    print(f"v1 = {v1}")
    print(f"v2 = {v2}")
    print(f"v3 = {v3}")
    print()
    print(f"欧氏距离:")
    print(f"  d(v1, v2) = {dist_12:.3f}")
    print(f"  d(v1, v3) = {dist_13:.3f}")
    print(f"  d(v2, v3) = {dist_23:.3f}")
    
    # 验证与numpy的结果
    print(f"\nNumPy验证:")
    print(f"  d(v1, v2) = {np.linalg.norm(v1 - v2):.3f}")
    print(f"  d(v1, v3) = {np.linalg.norm(v1 - v3):.3f}")
    print(f"  d(v2, v3) = {np.linalg.norm(v2 - v3):.3f}")
    
    # 欧氏距离的性质
    print(f"\n欧氏距离的性质:")
    print(f"1. 非负性: d(a,b) ≥ 0")
    print(f"2. 对称性: d(a,b) = d(b,a)")
    print(f"3. 三角不等式: d(a,c) ≤ d(a,b) + d(b,c)")
    print(f"4. 距离为0当且仅当向量相等")
    
    # 转换为相似度
    # 相似度 = 1 / (1 + 距离)
    sim_12 = 1 / (1 + dist_12)
    sim_13 = 1 / (1 + dist_13)
    sim_23 = 1 / (1 + dist_23)
    
    print(f"\n转换为相似度 (1/(1+距离)):")
    print(f"  sim(v1, v2) = {sim_12:.3f}")
    print(f"  sim(v1, v3) = {sim_13:.3f}")
    print(f"  sim(v2, v3) = {sim_23:.3f}")
    
    # 应用场景
    print(f"\n应用场景:")
    print(f"• 聚类算法 (K-means)")
    print(f"• 最近邻分类")
    print(f"• 异常检测")
    print(f"• 图像处理")
    
    return dist_12, dist_13, dist_23

euclidean_distances = euclidean_distance_analysis()
```

### 2. 余弦相似度 (Cosine Similarity)
```python
def cosine_similarity_analysis():
    """余弦相似度详解"""
    
    print("\n余弦相似度 (Cosine Similarity)")
    print("=" * 50)
    
    # 定义向量
    v1 = np.array([1, 2, 3])
    v2 = np.array([2, 4, 6])  # v1 的 2倍
    v3 = np.array([1, 0, 0])  # 与v1垂直
    v4 = np.array([-1, -2, -3])  # v1 的反向
    
    # 手工计算余弦相似度
    def cosine_similarity(a, b):
        dot_product = np.dot(a, b)
        norm_a = np.linalg.norm(a)
        norm_b = np.linalg.norm(b)
        return dot_product / (norm_a * norm_b)
    
    # 计算相似度
    cos_12 = cosine_similarity(v1, v2)
    cos_13 = cosine_similarity(v1, v3)
    cos_14 = cosine_similarity(v1, v4)
    
    print(f"v1 = {v1}")
    print(f"v2 = {v2} (v1的2倍)")
    print(f"v3 = {v3} (与v1垂直)")
    print(f"v4 = {v4} (v1的反向)")
    print()
    print(f"余弦相似度:")
    print(f"  cos(v1, v2) = {cos_12:.3f}")
    print(f"  cos(v1, v3) = {cos_13:.3f}")
    print(f"  cos(v1, v4) = {cos_14:.3f}")
    
    # 几何意义
    print(f"\n几何意义:")
    print(f"• cos = 1: 完全相同方向")
    print(f"• cos = 0: 垂直")
    print(f"• cos = -1: 完全相反方向")
    
    # 角度计算
    angle_12 = np.arccos(np.clip(cos_12, -1, 1))
    angle_13 = np.arccos(np.clip(cos_13, -1, 1))
    angle_14 = np.arccos(np.clip(cos_14, -1, 1))
    
    print(f"\n对应角度:")
    print(f"  ∠(v1, v2) = {np.degrees(angle_12):.1f}°")
    print(f"  ∠(v1, v3) = {np.degrees(angle_13):.1f}°")
    print(f"  ∠(v1, v4) = {np.degrees(angle_14):.1f}°")
    
    # 与欧氏距离的比较
    print(f"\n与欧氏距离的比较:")
    print(f"余弦相似度关注方向，欧氏距离关注位置")
    
    euclidean_12 = np.linalg.norm(v1 - v2)
    euclidean_13 = np.linalg.norm(v1 - v3)
    
    print(f"  v1 vs v2: 余弦={cos_12:.3f}, 欧氏={euclidean_12:.3f}")
    print(f"  v1 vs v3: 余弦={cos_13:.3f}, 欧氏={euclidean_13:.3f}")
    print(f"  v1和v2方向相同但距离远，v1和v3距离近但方向不同")
    
    # 应用场景
    print(f"\n应用场景:")
    print(f"• 文本相似度")
    print(f"• 推荐系统")
    print(f"• 信息检索")
    print(f"• 图像识别")
    
    return cos_12, cos_13, cos_14

cosine_similarities = cosine_similarity_analysis()
```

### 3. 点积相似度 (Dot Product)
```python
def dot_product_similarity_analysis():
    """点积相似度详解"""
    
    print("\n点积相似度 (Dot Product)")
    print("=" * 50)
    
    # 定义向量
    v1 = np.array([1, 2, 3])
    v2 = np.array([2, 4, 6])
    v3 = np.array([1, 0, 0])
    v4 = np.array([0, 1, 0])
    
    # 计算点积
    dot_12 = np.dot(v1, v2)
    dot_13 = np.dot(v1, v3)
    dot_14 = np.dot(v1, v4)
    dot_34 = np.dot(v3, v4)
    
    print(f"v1 = {v1}")
    print(f"v2 = {v2}")
    print(f"v3 = {v3}")
    print(f"v4 = {v4}")
    print()
    print(f"点积:")
    print(f"  v1 · v2 = {dot_12}")
    print(f"  v1 · v3 = {dot_13}")
    print(f"  v1 · v4 = {dot_14}")
    print(f"  v3 · v4 = {dot_34}")
    
    # 点积的计算方法
    print(f"\n点积的计算方法:")
    print(f"方法1: 对应元素相乘再求和")
    print(f"  v1 · v2 = 1×2 + 2×4 + 3×6 = {1*2 + 2*4 + 3*6}")
    
    print(f"\n方法2: 几何公式")
    print(f"  v1 · v2 = ||v1|| × ||v2|| × cos(θ)")
    norm_v1 = np.linalg.norm(v1)
    norm_v2 = np.linalg.norm(v2)
    cos_angle = dot_12 / (norm_v1 * norm_v2)
    print(f"  = {norm_v1:.3f} × {norm_v2:.3f} × {cos_angle:.3f} = {norm_v1 * norm_v2 * cos_angle:.3f}")
    
    # 点积的性质
    print(f"\n点积的性质:")
    print(f"1. 交换律: a · b = b · a")
    print(f"2. 分配律: a · (b + c) = a · b + a · c")
    print(f"3. 标量乘法: (ka) · b = k(a · b)")
    print(f"4. 正交性: 如果 a · b = 0，则 a ⊥ b")
    
    # 验证正交性
    print(f"\n正交性验证:")
    print(f"  v3 · v4 = {dot_34} (v3 和 v4 正交)")
    
    # 点积与相似度的关系
    print(f"\n点积与相似度的关系:")
    print(f"• 点积 > 0: 夹角 < 90°, 方向相似")
    print(f"• 点积 = 0: 夹角 = 90°, 正交")
    print(f"• 点积 < 0: 夹角 > 90°, 方向相反")
    
    # 应用场景
    print(f"\n应用场景:")
    print(f"• 神经网络 (权重计算)")
    print(f"• 线性代数运算")
    print(f"• 物理学 (功的计算)")
    print(f"• 机器学习 (特征重要性)")
    
    return dot_12, dot_13, dot_14

dot_products = dot_product_similarity_analysis()
```

### 4. 曼哈顿距离 (Manhattan Distance)
```python
def manhattan_distance_analysis():
    """曼哈顿距离详解"""
    
    print("\n曼哈顿距离 (Manhattan Distance)")
    print("=" * 50)
    
    # 定义向量
    v1 = np.array([1, 2, 3])
    v2 = np.array([4, 5, 6])
    v3 = np.array([1, 2, 4])
    
    # 计算曼哈顿距离
    def manhattan_distance(a, b):
        return np.sum(np.abs(a - b))
    
    # 计算距离
    man_12 = manhattan_distance(v1, v2)
    man_13 = manhattan_distance(v1, v3)
    man_23 = manhattan_distance(v2, v3)
    
    print(f"v1 = {v1}")
    print(f"v2 = {v2}")
    print(f"v3 = {v3}")
    print()
    print(f"曼哈顿距离:")
    print(f"  d_M(v1, v2) = {man_12}")
    print(f"  d_M(v1, v3) = {man_13}")
    print(f"  d_M(v2, v3) = {man_23}")
    
    # 计算过程展示
    print(f"\n计算过程 (v1, v2):")
    diff = np.abs(v1 - v2)
    print(f"  |v1 - v2| = {diff}")
    print(f"  sum = {diff[0]} + {diff[1]} + {diff[2]} = {man_12}")
    
    # 与欧氏距离比较
    euclidean_12 = np.linalg.norm(v1 - v2)
    euclidean_13 = np.linalg.norm(v1 - v3)
    
    print(f"\n与欧氏距离的比较:")
    print(f"  v1 vs v2: 曼哈顿={man_12}, 欧氏={euclidean_12:.3f}")
    print(f"  v1 vs v3: 曼哈顿={man_13}, 欧氏={euclidean_13:.3f}")
    
    # 几何意义
    print(f"\n几何意义:")
    print(f"• 曼哈顿距离: 城市街区距离，只能沿坐标轴移动")
    print(f"• 欧氏距离: 直线距离，可以任意方向移动")
    
    # 应用场景
    print(f"\n应用场景:")
    print(f"• 出租车路径规划")
    print(f"• 图像处理 (像素差异)")
    print(f"• 稀疏数据处理")
    print(f"• 异常检测")
    
    return man_12, man_13, man_23

manhattan_distances = manhattan_distance_analysis()
```

### 5. 皮尔逊相关系数 (Pearson Correlation)
```python
def pearson_correlation_analysis():
    """皮尔逊相关系数详解"""
    
    print("\n皮尔逊相关系数 (Pearson Correlation)")
    print("=" * 50)
    
    # 定义向量
    v1 = np.array([1, 2, 3, 4, 5])
    v2 = np.array([2, 4, 6, 8, 10])  # 完全正相关
    v3 = np.array([5, 4, 3, 2, 1])   # 完全负相关
    v4 = np.array([1, 5, 2, 4, 3])   # 无相关
    
    # 手工计算皮尔逊相关系数
    def pearson_correlation(a, b):
        # 中心化
        a_centered = a - np.mean(a)
        b_centered = b - np.mean(b)
        
        # 协方差
        covariance = np.mean(a_centered * b_centered)
        
        # 标准差
        std_a = np.std(a)
        std_b = np.std(b)
        
        # 相关系数
        correlation = covariance / (std_a * std_b)
        
        return correlation
    
    # 计算相关系数
    corr_12 = pearson_correlation(v1, v2)
    corr_13 = pearson_correlation(v1, v3)
    corr_14 = pearson_correlation(v1, v4)
    
    print(f"v1 = {v1}")
    print(f"v2 = {v2} (完全正相关)")
    print(f"v3 = {v3} (完全负相关)")
    print(f"v4 = {v4} (无相关)")
    print()
    print(f"皮尔逊相关系数:")
    print(f"  r(v1, v2) = {corr_12:.3f}")
    print(f"  r(v1, v3) = {corr_13:.3f}")
    print(f"  r(v1, v4) = {corr_14:.3f}")
    
    # 使用NumPy验证
    print(f"\nNumPy验证:")
    print(f"  r(v1, v2) = {np.corrcoef(v1, v2)[0,1]:.3f}")
    print(f"  r(v1, v3) = {np.corrcoef(v1, v3)[0,1]:.3f}")
    print(f"  r(v1, v4) = {np.corrcoef(v1, v4)[0,1]:.3f}")
    
    # 相关系数的意义
    print(f"\n相关系数的意义:")
    print(f"• r = 1: 完全正相关")
    print(f"• r = 0: 无线性相关")
    print(f"• r = -1: 完全负相关")
    print(f"• |r| > 0.7: 强相关")
    print(f"• 0.3 < |r| < 0.7: 中等相关")
    print(f"• |r| < 0.3: 弱相关")
    
    # 详细计算过程
    print(f"\n详细计算过程 (v1, v2):")
    v1_mean = np.mean(v1)
    v2_mean = np.mean(v2)
    print(f"  v1均值: {v1_mean}")
    print(f"  v2均值: {v2_mean}")
    
    v1_centered = v1 - v1_mean
    v2_centered = v2 - v2_mean
    print(f"  v1中心化: {v1_centered}")
    print(f"  v2中心化: {v2_centered}")
    
    covariance = np.mean(v1_centered * v2_centered)
    std_v1 = np.std(v1)
    std_v2 = np.std(v2)
    print(f"  协方差: {covariance:.3f}")
    print(f"  v1标准差: {std_v1:.3f}")
    print(f"  v2标准差: {std_v2:.3f}")
    print(f"  相关系数: {covariance:.3f} / ({std_v1:.3f} × {std_v2:.3f}) = {corr_12:.3f}")
    
    # 应用场景
    print(f"\n应用场景:")
    print(f"• 金融分析 (股票相关性)")
    print(f"• 推荐系统 (用户相似性)")
    print(f"• 特征选择 (特征相关性)")
    print(f"• 质量控制 (变量关系)")
    
    return corr_12, corr_13, corr_14

pearson_correlations = pearson_correlation_analysis()
```

---

## 🎯 实际应用案例

### 案例1：推荐系统中的相似度计算
```python
def recommendation_system_similarity():
    """推荐系统中的相似度计算"""
    
    print("推荐系统中的相似度计算")
    print("=" * 50)
    
    # 用户-物品评分矩阵
    # 行: 用户, 列: 物品
    ratings = np.array([
        [5, 3, 0, 1, 4],  # 用户1
        [4, 0, 0, 1, 5],  # 用户2
        [1, 1, 0, 5, 4],  # 用户3
        [0, 0, 5, 4, 0],  # 用户4
        [0, 3, 4, 4, 3]   # 用户5
    ])
    
    users = ['Alice', 'Bob', 'Carol', 'Dave', 'Eve']
    items = ['电影A', '电影B', '电影C', '电影D', '电影E']
    
    print("用户-物品评分矩阵:")
    print("       ", " ".join(f"{item:>6}" for item in items))
    for i, user in enumerate(users):
        print(f"{user:>7}", " ".join(f"{ratings[i,j]:>6}" for j in range(len(items))))
    
    # 计算用户相似度
    print(f"\n用户相似度计算:")
    
    def compute_user_similarity(ratings_matrix):
        """计算用户间的相似度"""
        n_users = ratings_matrix.shape[0]
        similarity_matrix = np.zeros((n_users, n_users))
        
        for i in range(n_users):
            for j in range(n_users):
                if i != j:
                    # 找到两个用户都评分过的物品
                    user_i = ratings_matrix[i]
                    user_j = ratings_matrix[j]
                    
                    # 过滤掉0评分（未评分）
                    mask = (user_i > 0) & (user_j > 0)
                    
                    if np.sum(mask) > 0:
                        # 使用皮尔逊相关系数
                        if np.sum(mask) > 1:
                            corr = np.corrcoef(user_i[mask], user_j[mask])[0,1]
                            if not np.isnan(corr):
                                similarity_matrix[i, j] = corr
                        else:
                            # 如果只有一个共同评分，使用余弦相似度
                            similarity_matrix[i, j] = np.dot(user_i[mask], user_j[mask]) / (
                                np.linalg.norm(user_i[mask]) * np.linalg.norm(user_j[mask])
                            )
                else:
                    similarity_matrix[i, j] = 1.0
        
        return similarity_matrix
    
    user_similarity = compute_user_similarity(ratings)
    
    print("用户相似度矩阵:")
    print("       ", " ".join(f"{user:>8}" for user in users))
    for i, user in enumerate(users):
        print(f"{user:>7}", " ".join(f"{user_similarity[i,j]:>8.3f}" for j in range(len(users))))
    
    # 为用户推荐物品
    def recommend_items(user_idx, ratings_matrix, similarity_matrix, n_recommendations=2):
        """为用户推荐物品"""
        target_user = ratings_matrix[user_idx]
        
        # 找到未评分的物品
        unrated_items = np.where(target_user == 0)[0]
        
        if len(unrated_items) == 0:
            return []
        
        # 计算每个未评分物品的预测评分
        predictions = []
        
        for item_idx in unrated_items:
            # 找到评分过该物品的用户
            rated_users = np.where(ratings_matrix[:, item_idx] > 0)[0]
            
            if len(rated_users) == 0:
                continue
            
            # 计算加权平均评分
            numerator = 0
            denominator = 0
            
            for other_user in rated_users:
                if other_user != user_idx:
                    similarity = similarity_matrix[user_idx, other_user]
                    rating = ratings_matrix[other_user, item_idx]
                    
                    numerator += similarity * rating
                    denominator += abs(similarity)
            
            if denominator > 0:
                predicted_rating = numerator / denominator
                predictions.append((item_idx, predicted_rating))
        
        # 排序并返回top-N推荐
        predictions.sort(key=lambda x: x[1], reverse=True)
        return predictions[:n_recommendations]
    
    # 为Alice推荐物品
    alice_idx = 0
    recommendations = recommend_items(alice_idx, ratings, user_similarity)
    
    print(f"\n为{users[alice_idx]}推荐物品:")
    for item_idx, predicted_rating in recommendations:
        print(f"  {items[item_idx]}: 预测评分 {predicted_rating:.2f}")
    
    # 分析推荐结果
    print(f"\n推荐分析:")
    print(f"• 基于用户相似度的协同过滤")
    print(f"• 找到相似用户，推荐他们喜欢的物品")
    print(f"• 使用加权平均预测评分")
    
    return user_similarity, recommendations

user_similarity, recommendations = recommendation_system_similarity()
```

### 案例2：文本相似度计算
```python
def text_similarity_example():
    """文本相似度计算示例"""
    
    print("\n文本相似度计算示例")
    print("=" * 50)
    
    # 示例文档
    documents = [
        "机器学习是人工智能的一个重要分支",
        "深度学习是机器学习的一个子领域",
        "人工智能正在改变世界",
        "今天天气很好适合出去散步",
        "神经网络是深度学习的基础"
    ]
    
    print("文档集合:")
    for i, doc in enumerate(documents):
        print(f"  文档{i+1}: {doc}")
    
    # 简单的词袋模型
    def create_vocabulary(docs):
        """创建词汇表"""
        vocabulary = set()
        for doc in docs:
            words = doc.split()
            vocabulary.update(words)
        return sorted(list(vocabulary))
    
    def document_to_vector(doc, vocabulary):
        """将文档转换为向量"""
        words = doc.split()
        vector = np.zeros(len(vocabulary))
        
        for word in words:
            if word in vocabulary:
                idx = vocabulary.index(word)
                vector[idx] += 1
        
        return vector
    
    # 创建词汇表
    vocab = create_vocabulary(documents)
    print(f"\n词汇表: {vocab}")
    
    # 将文档转换为向量
    doc_vectors = []
    for doc in documents:
        vector = document_to_vector(doc, vocab)
        doc_vectors.append(vector)
    
    doc_vectors = np.array(doc_vectors)
    
    print(f"\n文档向量矩阵形状: {doc_vectors.shape}")
    print("文档向量:")
    for i, vector in enumerate(doc_vectors):
        print(f"  文档{i+1}: {vector}")
    
    # 计算文档间的相似度
    def compute_document_similarity(vectors):
        """计算文档间的相似度"""
        n_docs = len(vectors)
        similarity_matrix = np.zeros((n_docs, n_docs))
        
        for i in range(n_docs):
            for j in range(n_docs):
                if i != j:
                    # 使用余弦相似度
                    dot_product = np.dot(vectors[i], vectors[j])
                    norm_i = np.linalg.norm(vectors[i])
                    norm_j = np.linalg.norm(vectors[j])
                    
                    if norm_i > 0 and norm_j > 0:
                        similarity_matrix[i, j] = dot_product / (norm_i * norm_j)
                else:
                    similarity_matrix[i, j] = 1.0
        
        return similarity_matrix
    
    doc_similarity = compute_document_similarity(doc_vectors)
    
    print(f"\n文档相似度矩阵:")
    print("       ", " ".join(f"文档{i+1:>7}" for i in range(len(documents))))
    for i in range(len(documents)):
        print(f"文档{i+1:>5}", " ".join(f"{doc_similarity[i,j]:>7.3f}" for j in range(len(documents))))
    
    # 找到最相似的文档对
    max_similarity = 0
    most_similar_pair = None
    
    for i in range(len(documents)):
        for j in range(i+1, len(documents)):
            if doc_similarity[i, j] > max_similarity:
                max_similarity = doc_similarity[i, j]
                most_similar_pair = (i, j)
    
    if most_similar_pair:
        i, j = most_similar_pair
        print(f"\n最相似的文档对:")
        print(f"  文档{i+1}: {documents[i]}")
        print(f"  文档{j+1}: {documents[j]}")
        print(f"  相似度: {max_similarity:.3f}")
    
    # 给定查询，找到最相似的文档
    query = "深度学习和神经网络"
    query_vector = document_to_vector(query, vocab)
    
    print(f"\n查询: {query}")
    print(f"查询向量: {query_vector}")
    
    # 计算查询与所有文档的相似度
    query_similarities = []
    for i, doc_vector in enumerate(doc_vectors):
        dot_product = np.dot(query_vector, doc_vector)
        norm_query = np.linalg.norm(query_vector)
        norm_doc = np.linalg.norm(doc_vector)
        
        if norm_query > 0 and norm_doc > 0:
            similarity = dot_product / (norm_query * norm_doc)
        else:
            similarity = 0
        
        query_similarities.append((i, similarity))
    
    # 排序并显示结果
    query_similarities.sort(key=lambda x: x[1], reverse=True)
    
    print(f"\n查询结果 (按相似度排序):")
    for i, (doc_idx, similarity) in enumerate(query_similarities):
        print(f"  {i+1}. 文档{doc_idx+1}: {documents[doc_idx]} (相似度: {similarity:.3f})")
    
    return doc_similarity, query_similarities

doc_similarity, query_similarities = text_similarity_example()
```

### 案例3：图像相似度计算
```python
def image_similarity_example():
    """图像相似度计算示例"""
    
    print("\n图像相似度计算示例")
    print("=" * 50)
    
    # 模拟图像数据（简化为小图像）
    np.random.seed(42)
    
    # 创建几个模拟图像 (8x8像素)
    def create_pattern_image(pattern_type, noise_level=0.1):
        """创建带有特定模式的图像"""
        img = np.zeros((8, 8))
        
        if pattern_type == 'vertical':
            img[:, 2:6] = 1
        elif pattern_type == 'horizontal':
            img[2:6, :] = 1
        elif pattern_type == 'diagonal':
            for i in range(8):
                if i < 8:
                    img[i, i] = 1
        elif pattern_type == 'circle':
            center = (4, 4)
            for i in range(8):
                for j in range(8):
                    if (i - center[0])**2 + (j - center[1])**2 <= 9:
                        img[i, j] = 1
        
        # 添加噪声
        img += noise_level * np.random.randn(8, 8)
        img = np.clip(img, 0, 1)
        
        return img
    
    # 创建图像集合
    images = {
        'vertical1': create_pattern_image('vertical', 0.05),
        'vertical2': create_pattern_image('vertical', 0.15),
        'horizontal1': create_pattern_image('horizontal', 0.05),
        'diagonal1': create_pattern_image('diagonal', 0.05),
        'circle1': create_pattern_image('circle', 0.05)
    }
    
    print("图像集合:")
    for name, img in images.items():
        print(f"  {name}: {img.shape} 像素")
    
    # 将图像转换为向量
    image_vectors = {}
    for name, img in images.items():
        image_vectors[name] = img.flatten()
    
    image_names = list(image_vectors.keys())
    vectors = np.array(list(image_vectors.values()))
    
    print(f"\n图像向量形状: {vectors.shape}")
    
    # 计算图像间的相似度
    def compute_image_similarity(vectors, names):
        """计算图像间的相似度"""
        n_images = len(vectors)
        similarity_matrix = np.zeros((n_images, n_images))
        
        for i in range(n_images):
            for j in range(n_images):
                if i != j:
                    # 使用多种相似度度量
                    
                    # 1. 余弦相似度
                    cosine_sim = np.dot(vectors[i], vectors[j]) / (
                        np.linalg.norm(vectors[i]) * np.linalg.norm(vectors[j])
                    )
                    
                    # 2. 皮尔逊相关系数
                    pearson_sim = np.corrcoef(vectors[i], vectors[j])[0, 1]
                    if np.isnan(pearson_sim):
                        pearson_sim = 0
                    
                    # 3. 结构相似性（简化版）
                    mse = np.mean((vectors[i] - vectors[j]) ** 2)
                    structural_sim = 1 / (1 + mse)
                    
                    # 综合相似度
                    similarity_matrix[i, j] = 0.4 * cosine_sim + 0.3 * pearson_sim + 0.3 * structural_sim
                else:
                    similarity_matrix[i, j] = 1.0
        
        return similarity_matrix
    
    img_similarity = compute_image_similarity(vectors, image_names)
    
    print(f"\n图像相似度矩阵:")
    print("            ", " ".join(f"{name:>12}" for name in image_names))
    for i, name in enumerate(image_names):
        print(f"{name:>12}", " ".join(f"{img_similarity[i,j]:>12.3f}" for j in range(len(image_names))))
    
    # 找到最相似的图像对
    max_similarity = 0
    most_similar_pair = None
    
    for i in range(len(image_names)):
        for j in range(i+1, len(image_names)):
            if img_similarity[i, j] > max_similarity:
                max_similarity = img_similarity[i, j]
                most_similar_pair = (i, j)
    
    if most_similar_pair:
        i, j = most_similar_pair
        print(f"\n最相似的图像对:")
        print(f"  {image_names[i]} vs {image_names[j]}")
        print(f"  相似度: {max_similarity:.3f}")
    
    # 图像检索示例
    query_image = create_pattern_image('vertical', 0.2)
    query_vector = query_image.flatten()
    
    print(f"\n查询图像: 垂直模式 (带噪声)")
    
    # 计算查询图像与所有图像的相似度
    query_similarities = []
    for i, img_vector in enumerate(vectors):
        cosine_sim = np.dot(query_vector, img_vector) / (
            np.linalg.norm(query_vector) * np.linalg.norm(img_vector)
        )
        query_similarities.append((i, cosine_sim))
    
    # 排序并显示结果
    query_similarities.sort(key=lambda x: x[1], reverse=True)
    
    print(f"\n检索结果 (按相似度排序):")
    for i, (img_idx, similarity) in enumerate(query_similarities):
        print(f"  {i+1}. {image_names[img_idx]}: {similarity:.3f}")
    
    # 分析不同模式的相似性
    print(f"\n模式分析:")
    print(f"• 相同模式的图像相似度最高")
    print(f"• 噪声影响相似度计算")
    print(f"• 结构相似性比像素值相似性更重要")
    
    return img_similarity, query_similarities

img_similarity, query_similarities = image_similarity_example()
```

---

## 📊 相似度度量的选择指南

### 不同场景下的最佳选择
```python
def similarity_selection_guide():
    """相似度度量选择指南"""
    
    print("相似度度量选择指南")
    print("=" * 50)
    
    # 不同度量的特点
    metrics = {
        "欧氏距离": {
            "特点": ["考虑绝对位置", "对异常值敏感", "适合连续数据"],
            "优点": ["直观易懂", "计算简单", "几何意义明确"],
            "缺点": ["维度灾难", "尺度敏感", "不适合稀疏数据"],
            "适用场景": ["聚类分析", "最近邻分类", "异常检测", "图像处理"]
        },
        
        "余弦相似度": {
            "特点": ["关注方向", "忽略大小", "适合高维数据"],
            "优点": ["尺度不敏感", "适合稀疏数据", "计算效率高"],
            "缺点": ["忽略数值大小", "对零向量敏感"],
            "适用场景": ["文本分析", "推荐系统", "信息检索", "特征匹配"]
        },
        
        "皮尔逊相关": {
            "特点": ["线性关系", "标准化处理", "统计意义"],
            "优点": ["反映线性关系", "消除均值影响", "统计显著性"],
            "缺点": ["只捕捉线性关系", "对异常值敏感"],
            "适用场景": ["金融分析", "推荐系统", "特征选择", "质量控制"]
        },
        
        "曼哈顿距离": {
            "特点": ["L1范数", "对异常值较鲁棒", "稀疏友好"],
            "优点": ["异常值鲁棒性", "计算简单", "适合稀疏数据"],
            "缺点": ["不如欧氏距离直观", "可能过度惩罚"],
            "适用场景": ["稀疏数据", "异常检测", "路径规划", "图像处理"]
        }
    }
    
    for metric, info in metrics.items():
        print(f"\n{metric}:")
        print(f"  特点: {', '.join(info['特点'])}")
        print(f"  优点: {', '.join(info['优点'])}")
        print(f"  缺点: {', '.join(info['缺点'])}")
        print(f"  适用场景: {', '.join(info['适用场景'])}")
    
    # 选择决策树
    print(f"\n选择决策树:")
    print(f"├── 数据类型")
    print(f"│   ├── 文本数据 → 余弦相似度")
    print(f"│   ├── 图像数据 → 欧氏距离 或 结构相似度")
    print(f"│   ├── 评分数据 → 皮尔逊相关")
    print(f"│   └── 二进制数据 → Jaccard系数")
    print(f"│")
    print(f"├── 数据特征")
    print(f"│   ├── 高维稀疏 → 余弦相似度")
    print(f"│   ├── 低维密集 → 欧氏距离")
    print(f"│   ├── 有异常值 → 曼哈顿距离")
    print(f"│   └── 需要标准化 → 皮尔逊相关")
    print(f"│")
    print(f"└── 应用场景")
    print(f"    ├── 聚类分析 → 欧氏距离")
    print(f"    ├── 推荐系统 → 余弦相似度 或 皮尔逊相关")
    print(f"    ├── 信息检索 → 余弦相似度")
    print(f"    └── 异常检测 → 曼哈顿距离 或 马氏距离")
    
    # 性能比较
    print(f"\n性能比较:")
    
    # 生成测试数据
    np.random.seed(42)
    n_samples = 1000
    n_features = 100
    
    X = np.random.randn(n_samples, n_features)
    
    # 测试不同度量的计算时间
    import time
    
    # 选择两个向量进行比较
    v1 = X[0]
    v2 = X[1]
    
    # 测试函数
    def time_function(func, *args, n_runs=1000):
        start = time.time()
        for _ in range(n_runs):
            func(*args)
        end = time.time()
        return (end - start) / n_runs
    
    # 定义度量函数
    def euclidean_sim(a, b):
        return 1 / (1 + np.linalg.norm(a - b))
    
    def cosine_sim(a, b):
        return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))
    
    def manhattan_sim(a, b):
        return 1 / (1 + np.sum(np.abs(a - b)))
    
    def pearson_sim(a, b):
        return np.corrcoef(a, b)[0, 1]
    
    # 测试时间
    functions = [
        ("欧氏距离", euclidean_sim),
        ("余弦相似度", cosine_sim),
        ("曼哈顿距离", manhattan_sim),
        ("皮尔逊相关", pearson_sim)
    ]
    
    print(f"  计算时间比较 (向量维度: {n_features}):")
    for name, func in functions:
        avg_time = time_function(func, v1, v2)
        print(f"    {name}: {avg_time*1000:.4f} ms")

similarity_selection_guide()
```

---

## 🚀 优化技巧

### 高效计算大规模相似度
```python
def efficient_similarity_computation():
    """高效计算大规模相似度"""
    
    print("高效计算大规模相似度")
    print("=" * 50)
    
    # 生成大规模数据
    np.random.seed(42)
    n_samples = 5000
    n_features = 100
    
    X = np.random.randn(n_samples, n_features)
    
    print(f"数据规模: {X.shape}")
    print(f"如果计算所有对的相似度，需要 {n_samples * (n_samples - 1) // 2:,} 次计算")
    
    import time
    
    # 方法1: 朴素方法 - 双重循环
    print(f"\n方法1: 朴素方法")
    start = time.time()
    
    # 只计算前100个样本的相似度矩阵
    subset_size = 100
    similarity_naive = np.zeros((subset_size, subset_size))
    
    for i in range(subset_size):
        for j in range(subset_size):
            if i != j:
                similarity_naive[i, j] = np.dot(X[i], X[j]) / (
                    np.linalg.norm(X[i]) * np.linalg.norm(X[j])
                )
            else:
                similarity_naive[i, j] = 1.0
    
    time_naive = time.time() - start
    print(f"  时间: {time_naive:.4f}秒 (仅{subset_size}个样本)")
    
    # 方法2: 向量化计算
    print(f"\n方法2: 向量化计算")
    start = time.time()
    
    # 标准化数据
    X_normalized = X / np.linalg.norm(X, axis=1, keepdims=True)
    
    # 计算所有对的余弦相似度
    similarity_vectorized = X_normalized @ X_normalized.T
    
    time_vectorized = time.time() - start
    print(f"  时间: {time_vectorized:.4f}秒 (全部{n_samples}个样本)")
    print(f"  速度提升: {time_naive / time_vectorized:.1f}倍")
    
    # 方法3: 稀疏相似度计算 (只计算相似度高的对)
    print(f"\n方法3: 稀疏相似度计算")
    start = time.time()
    
    # 设置相似度阈值
    threshold = 0.8
    
    # 使用近似方法：随机投影
    from sklearn.random_projection import SparseRandomProjection
    
    # 降维到较低维度
    reducer = SparseRandomProjection(n_components=50, random_state=42)
    X_reduced = reducer.fit_transform(X)
    
    # 在低维空间计算相似度
    X_reduced_norm = X_reduced / np.linalg.norm(X_reduced, axis=1, keepdims=True)
    similarity_reduced = X_reduced_norm @ X_reduced_norm.T
    
    # 只保留高相似度的对
    high_similarity_pairs = np.where(similarity_reduced > threshold)
    
    time_sparse = time.time() - start
    print(f"  时间: {time_sparse:.4f}秒")
    print(f"  高相似度对数: {len(high_similarity_pairs[0]):,}")
    print(f"  压缩比: {len(high_similarity_pairs[0]) / (n_samples * n_samples):.4f}")
    
    # 方法4: 分块计算
    print(f"\n方法4: 分块计算")
    start = time.time()
    
    block_size = 1000
    n_blocks = (n_samples + block_size - 1) // block_size
    
    # 只计算对角线块
    block_similarities = []
    for i in range(n_blocks):
        start_idx = i * block_size
        end_idx = min(start_idx + block_size, n_samples)
        
        block_data = X[start_idx:end_idx]
        block_norm = block_data / np.linalg.norm(block_data, axis=1, keepdims=True)
        block_sim = block_norm @ block_norm.T
        
        block_similarities.append(block_sim)
    
    time_block = time.time() - start
    print(f"  时间: {time_block:.4f}秒")
    print(f"  处理了 {n_blocks} 个块")
    
    # 方法5: 近似最近邻
    print(f"\n方法5: 近似最近邻")
    
    try:
        from sklearn.neighbors import NearestNeighbors
        
        start = time.time()
        
        # 使用近似最近邻算法
        nbrs = NearestNeighbors(n_neighbors=10, algorithm='auto', metric='cosine')
        nbrs.fit(X)
        
        # 为每个样本找到最相似的k个邻居
        distances, indices = nbrs.kneighbors(X)
        
        time_ann = time.time() - start
        print(f"  时间: {time_ann:.4f}秒")
        print(f"  为每个样本找到 {10} 个最相似的邻居")
        print(f"  总相似度对数: {n_samples * 10:,}")
        
    except ImportError:
        print("  需要安装 scikit-learn")
    
    # 内存使用分析
    print(f"\n内存使用分析:")
    full_matrix_size = n_samples * n_samples * 8  # 8字节per float64
    print(f"  完整相似度矩阵: {full_matrix_size / (1024**3):.2f} GB")
    
    sparse_matrix_size = len(high_similarity_pairs[0]) * 8 * 3  # 行、列、值
    print(f"  稀疏相似度矩阵: {sparse_matrix_size / (1024**2):.2f} MB")
    
    # 总结
    print(f"\n优化总结:")
    print(f"• 向量化计算: 最大的性能提升")
    print(f"• 稀疏计算: 节省内存和计算")
    print(f"• 分块处理: 适合超大数据集")
    print(f"• 近似方法: 平衡精度和效率")
    print(f"• 降维预处理: 减少计算复杂度")

efficient_similarity_computation()
```

---

## 📚 总结与建议

### 向量相似度的完整总结
```python
def vector_similarity_summary():
    """向量相似度的完整总结"""
    
    print("向量相似度完整总结")
    print("=" * 50)
    
    # 度量方法总结
    print("主要度量方法:")
    print("1. 欧氏距离 - 位置相似度")
    print("2. 余弦相似度 - 方向相似度")
    print("3. 皮尔逊相关 - 线性关系")
    print("4. 曼哈顿距离 - 鲁棒性好")
    print("5. 点积 - 简单高效")
    
    # 选择建议
    print(f"\n选择建议:")
    scenarios = [
        ("文本分析", "余弦相似度", "关注词语共现模式"),
        ("图像匹配", "欧氏距离", "像素级差异重要"),
        ("推荐系统", "皮尔逊相关", "用户评分行为"),
        ("异常检测", "曼哈顿距离", "对异常值鲁棒"),
        ("神经网络", "点积", "计算效率高")
    ]
    
    for scenario, method, reason in scenarios:
        print(f"  {scenario}: {method} ({reason})")
    
    # 实现要点
    print(f"\n实现要点:")
    print("• 数据预处理: 标准化、归一化")
    print("• 维度处理: 降维、特征选择")
    print("• 计算优化: 向量化、并行化")
    print("• 内存管理: 分块、稀疏存储")
    print("• 结果验证: 交叉验证、可视化")
    
    # 常见陷阱
    print(f"\n常见陷阱:")
    print("• 忘记标准化数据")
    print("• 高维空间的距离意义")
    print("• 稀疏数据的零值处理")
    print("• 计算溢出和数值稳定性")
    print("• 相似度与距离的转换")
    
    # 扩展方向
    print(f"\n扩展方向:")
    print("• 学习相似度度量")
    print("• 多模态相似度")
    print("• 动态相似度")
    print("• 近似算法")
    print("• 分布式计算")

vector_similarity_summary()
```

---

## 🎯 学习建议

### 掌握向量相似度的关键步骤
1. **理解几何意义**：从二维空间开始理解向量关系
2. **熟悉数学公式**：掌握各种度量的计算方法
3. **实践编程实现**：手工实现加深理解
4. **应用场景分析**：知道在什么情况下使用哪种度量
5. **性能优化技巧**：学会处理大规模数据

### 深入学习建议
- **线性代数基础**：向量空间、内积、范数
- **统计学知识**：相关性、分布、假设检验
- **机器学习应用**：聚类、分类、推荐系统
- **算法优化**：并行计算、近似算法、分布式处理

---

**📐 记住：选择合适的相似度度量是成功应用的关键，理解其背后的数学原理和几何意义更为重要！** 