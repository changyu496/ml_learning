# ğŸ“¡ NumPyå¹¿æ’­æœºåˆ¶æ·±åº¦è§£æ

## ğŸ¯ æ ¸å¿ƒæ¦‚å¿µ

> **å¹¿æ’­æœºåˆ¶æ˜¯NumPyæœ€ç¥å¥‡çš„ç‰¹æ€§ä¹‹ä¸€ï¼Œå®ƒè®©ä¸åŒå½¢çŠ¶çš„æ•°ç»„èƒ½å¤Ÿæ— ç¼é…åˆè¿ç®—**

### ä»€ä¹ˆæ˜¯å¹¿æ’­ï¼Ÿ
**å®šä¹‰**ï¼šå¹¿æ’­æ˜¯NumPyåœ¨ç®—æœ¯è¿ç®—æœŸé—´å¤„ç†ä¸åŒå½¢çŠ¶æ•°ç»„çš„è§„åˆ™ã€‚

**æ ¸å¿ƒæ€æƒ³**ï¼šè®©è¾ƒå°çš„æ•°ç»„åœ¨è¾ƒå¤§çš„æ•°ç»„ä¸Š"å¹¿æ’­"ï¼Œä½¿å®ƒä»¬å…·æœ‰å…¼å®¹çš„å½¢çŠ¶ã€‚

---

## ğŸ§© å¹¿æ’­çš„åŸºæœ¬è§„åˆ™

### è§„åˆ™æ€»è§ˆ
NumPyçš„å¹¿æ’­éµå¾ªä»¥ä¸‹è§„åˆ™ï¼š

1. **ä»å°¾éƒ¨ç»´åº¦å¼€å§‹æ¯”è¾ƒ**
2. **ç»´åº¦å¤§å°ç›¸ç­‰ æˆ– å…¶ä¸­ä¸€ä¸ªä¸º1** â†’ å…¼å®¹
3. **ç¼ºå¤±çš„ç»´åº¦è¢«è§†ä¸º1**
4. **ç»“æœçš„å½¢çŠ¶æ˜¯æ¯ä¸ªç»´åº¦çš„æœ€å¤§å€¼**

### å¯è§†åŒ–ç†è§£
```python
import numpy as np

# ç¤ºä¾‹1ï¼šæ ‡é‡ä¸æ•°ç»„
a = np.array([1, 2, 3, 4])     # å½¢çŠ¶: (4,)
b = 5                          # å½¢çŠ¶: ()

# å¹¿æ’­è¿‡ç¨‹ï¼š
# a: (4,)
# b: ()  -> (1,) -> (4,)  [å¹¿æ’­]
result = a + b  # [6, 7, 8, 9]
```

---

## ğŸ“ å¹¿æ’­è§„åˆ™è¯¦è§£

### æƒ…å†µ1ï¼šç»´åº¦æ•°ç›¸åŒ
```python
# ç¤ºä¾‹ï¼š3x3 çŸ©é˜µ + 3x1 çŸ©é˜µ
A = np.array([[1, 2, 3],
              [4, 5, 6],
              [7, 8, 9]])    # å½¢çŠ¶: (3, 3)

B = np.array([[10],
              [20],
              [30]])         # å½¢çŠ¶: (3, 1)

# å¹¿æ’­è¿‡ç¨‹ï¼š
# A: (3, 3)
# B: (3, 1) -> (3, 3)  [ç¬¬äºŒç»´ä»1æ‰©å±•åˆ°3]
result = A + B

print("A + B =")
print(result)
# è¾“å‡ºï¼š
# [[11 12 13]
#  [24 25 26]
#  [37 38 39]]
```

### æƒ…å†µ2ï¼šç»´åº¦æ•°ä¸åŒ
```python
# ç¤ºä¾‹ï¼š2x3 çŸ©é˜µ + 1Dæ•°ç»„
A = np.array([[1, 2, 3],
              [4, 5, 6]])    # å½¢çŠ¶: (2, 3)

B = np.array([10, 20, 30])   # å½¢çŠ¶: (3,)

# å¹¿æ’­è¿‡ç¨‹ï¼š
# A: (2, 3)
# B: (3,) -> (1, 3) -> (2, 3)  [æ·»åŠ ç»´åº¦å¹¶æ‰©å±•]
result = A + B

print("A + B =")
print(result)
# è¾“å‡ºï¼š
# [[11 22 33]
#  [14 25 36]]
```

### æƒ…å†µ3ï¼šå¤æ‚å¹¿æ’­
```python
# ç¤ºä¾‹ï¼šå¤šç»´å¹¿æ’­
A = np.random.randn(8, 1, 6, 1)    # å½¢çŠ¶: (8, 1, 6, 1)
B = np.random.randn(7, 1, 5)       # å½¢çŠ¶: (7, 1, 5)

# å¹¿æ’­è¿‡ç¨‹ï¼š
# A: (8, 1, 6, 1)
# B: (   7, 1, 5) -> (1, 7, 1, 5) -> (8, 7, 6, 5)
# ç»“æœå½¢çŠ¶: (8, 7, 6, 5)

result = A + B
print(f"ç»“æœå½¢çŠ¶: {result.shape}")
```

---

## ğŸ’¡ å¹¿æ’­çš„å®é™…åº”ç”¨

### 1. æ•°æ®æ ‡å‡†åŒ–
```python
# æ•°æ®çŸ©é˜µï¼š100ä¸ªæ ·æœ¬ï¼Œ5ä¸ªç‰¹å¾
data = np.random.randn(100, 5)

# æ–¹æ³•1ï¼šæ‰‹åŠ¨å¾ªç¯ï¼ˆä¸æ¨èï¼‰
standardized_manual = np.zeros_like(data)
for i in range(data.shape[1]):
    col = data[:, i]
    standardized_manual[:, i] = (col - col.mean()) / col.std()

# æ–¹æ³•2ï¼šä½¿ç”¨å¹¿æ’­ï¼ˆæ¨èï¼‰
means = data.mean(axis=0)      # å½¢çŠ¶: (5,)
stds = data.std(axis=0)        # å½¢çŠ¶: (5,)
standardized_broadcast = (data - means) / stds  # å¹¿æ’­ï¼

print(f"æ•°æ®å½¢çŠ¶: {data.shape}")
print(f"å‡å€¼å½¢çŠ¶: {means.shape}")
print(f"æ ‡å‡†å·®å½¢çŠ¶: {stds.shape}")
print(f"ç»“æœå½¢çŠ¶: {standardized_broadcast.shape}")

# éªŒè¯ç»“æœç›¸åŒ
print(f"ç»“æœç›¸åŒ: {np.allclose(standardized_manual, standardized_broadcast)}")
```

### 2. å›¾åƒæ‰¹å¤„ç†
```python
# æ¨¡æ‹Ÿå›¾åƒæ‰¹æ¬¡ï¼š32å¼ 64x64çš„RGBå›¾åƒ
images = np.random.randint(0, 256, (32, 64, 64, 3))

# æ¯ä¸ªé€šé“çš„å…¨å±€å‡å€¼
channel_means = np.array([123.68, 116.78, 103.94])  # å½¢çŠ¶: (3,)

# å‡å»å‡å€¼è¿›è¡Œä¸­å¿ƒåŒ–
# images: (32, 64, 64, 3)
# channel_means: (3,) -> (1, 1, 1, 3) -> (32, 64, 64, 3)
centered_images = images - channel_means

print(f"åŸå§‹å›¾åƒå½¢çŠ¶: {images.shape}")
print(f"é€šé“å‡å€¼å½¢çŠ¶: {channel_means.shape}")
print(f"ä¸­å¿ƒåŒ–åå½¢çŠ¶: {centered_images.shape}")
```

### 3. è·ç¦»è®¡ç®—
```python
# è®¡ç®—æ‰€æœ‰ç‚¹å¯¹ä¹‹é—´çš„è·ç¦»
points_A = np.random.randn(5, 2)    # 5ä¸ª2Dç‚¹
points_B = np.random.randn(3, 2)    # 3ä¸ª2Dç‚¹

# ä½¿ç”¨å¹¿æ’­è®¡ç®—è·ç¦»çŸ©é˜µ
# points_A[:, np.newaxis]: (5, 1, 2)
# points_B: (3, 2) -> (1, 3, 2)
# ç»“æœ: (5, 3, 2)
differences = points_A[:, np.newaxis] - points_B
distances = np.sqrt((differences ** 2).sum(axis=2))

print(f"Aä¸­çš„ç‚¹æ•°: {points_A.shape[0]}")
print(f"Bä¸­çš„ç‚¹æ•°: {points_B.shape[0]}")
print(f"è·ç¦»çŸ©é˜µå½¢çŠ¶: {distances.shape}")
print("è·ç¦»çŸ©é˜µ:")
print(distances)
```

---

## ğŸ¨ å¹¿æ’­æŠ€å·§å¤§å…¨

### 1. å¢åŠ ç»´åº¦çš„æŠ€å·§
```python
arr = np.array([1, 2, 3, 4, 5])  # å½¢çŠ¶: (5,)

# è½¬æ¢ä¸ºåˆ—å‘é‡
col_vector = arr[:, np.newaxis]   # å½¢çŠ¶: (5, 1)
# æˆ–è€…
col_vector = arr.reshape(-1, 1)   # å½¢çŠ¶: (5, 1)

# è½¬æ¢ä¸ºè¡Œå‘é‡
row_vector = arr[np.newaxis, :]   # å½¢çŠ¶: (1, 5)
# æˆ–è€…
row_vector = arr.reshape(1, -1)   # å½¢çŠ¶: (1, 5)

print(f"åŸå§‹: {arr.shape}")
print(f"åˆ—å‘é‡: {col_vector.shape}")
print(f"è¡Œå‘é‡: {row_vector.shape}")
```

### 2. å¤–ç§¯è¿ç®—
```python
# è®¡ç®—å¤–ç§¯ï¼šä¸éœ€è¦å¾ªç¯ï¼
a = np.array([1, 2, 3])      # å½¢çŠ¶: (3,)
b = np.array([4, 5, 6, 7])   # å½¢çŠ¶: (4,)

# ä½¿ç”¨å¹¿æ’­è®¡ç®—å¤–ç§¯
outer_product = a[:, np.newaxis] * b  # (3, 1) * (4,) -> (3, 4)

print("å¤–ç§¯ç»“æœ:")
print(outer_product)
# è¾“å‡º:
# [[ 4  5  6  7]
#  [ 8 10 12 14]
#  [12 15 18 21]]

# éªŒè¯ï¼šä¸np.outerç»“æœç›¸åŒ
print(f"ä¸np.outerç›¸åŒ: {np.allclose(outer_product, np.outer(a, b))}")
```

### 3. æ¡ä»¶å¹¿æ’­
```python
# æ ¹æ®æ¡ä»¶è¿›è¡Œä¸åŒçš„å¹¿æ’­æ“ä½œ
data = np.random.randn(4, 5)
thresholds = np.array([0.5, -0.5, 1.0, 0.0, -1.0])  # æ¯åˆ—ä¸åŒé˜ˆå€¼

# å°†è¶…è¿‡é˜ˆå€¼çš„å€¼è®¾ä¸ºé˜ˆå€¼
clipped = np.where(data > thresholds, thresholds, data)

print(f"æ•°æ®å½¢çŠ¶: {data.shape}")
print(f"é˜ˆå€¼å½¢çŠ¶: {thresholds.shape}")
print(f"ç»“æœå½¢çŠ¶: {clipped.shape}")
```

---

## ğŸš€ é«˜çº§å¹¿æ’­æ¨¡å¼

### 1. å¤šç»´ç»Ÿè®¡è¿ç®—
```python
# 3Dæ•°æ®ï¼šæ—¶é—´åºåˆ—æ•°æ®ï¼ˆæ—¶é—´, æ ·æœ¬, ç‰¹å¾ï¼‰
time_series = np.random.randn(100, 50, 10)  # 100ä¸ªæ—¶é—´ç‚¹ï¼Œ50ä¸ªæ ·æœ¬ï¼Œ10ä¸ªç‰¹å¾

# è®¡ç®—æ¯ä¸ªç‰¹å¾åœ¨æ‰€æœ‰æ ·æœ¬ä¸Šçš„ç§»åŠ¨å¹³å‡
window_size = 5
moving_avg = np.zeros_like(time_series)

for t in range(window_size-1, len(time_series)):
    # ä½¿ç”¨å¹¿æ’­è®¡ç®—çª—å£å†…çš„å¹³å‡å€¼
    window_data = time_series[t-window_size+1:t+1]  # (5, 50, 10)
    moving_avg[t] = window_data.mean(axis=0)        # å¹¿æ’­åˆ° (50, 10)

print(f"åŸå§‹æ•°æ®å½¢çŠ¶: {time_series.shape}")
print(f"ç§»åŠ¨å¹³å‡å½¢çŠ¶: {moving_avg.shape}")
```

### 2. é«˜ç»´å¼ é‡æ“ä½œ
```python
# æ¨¡æ‹Ÿæ·±åº¦å­¦ä¹ ä¸­çš„å¼ é‡æ“ä½œ
batch_size, height, width, channels = 32, 28, 28, 3
images = np.random.randn(batch_size, height, width, channels)

# æ¯ä¸ªé€šé“çš„ä¸åŒæƒé‡
channel_weights = np.array([0.299, 0.587, 0.114])  # RGBåˆ°ç°åº¦çš„æƒé‡

# åŠ æƒæ±‚å’Œè½¬æ¢ä¸ºç°åº¦ï¼ˆå¹¿æ’­ï¼‰
# images: (32, 28, 28, 3)
# channel_weights: (3,) -> (1, 1, 1, 3)
grayscale = (images * channel_weights).sum(axis=3)

print(f"å½©è‰²å›¾åƒå½¢çŠ¶: {images.shape}")
print(f"ç°åº¦å›¾åƒå½¢çŠ¶: {grayscale.shape}")
```

---

## âš ï¸ å¹¿æ’­é™·é˜±ä¸è§£å†³æ–¹æ¡ˆ

### é™·é˜±1ï¼šæ„å¤–çš„å½¢çŠ¶å…¼å®¹
```python
# çœ‹èµ·æ¥ä¸å…¼å®¹ï¼Œä½†å®é™…ä¸Šæ˜¯å…¼å®¹çš„
A = np.random.randn(3, 1)    # å½¢çŠ¶: (3, 1)
B = np.random.randn(1, 4)    # å½¢çŠ¶: (1, 4)

# è¿™æ˜¯å…¼å®¹çš„ï¼ç»“æœå½¢çŠ¶æ˜¯ (3, 4)
result = A + B
print(f"Aå½¢çŠ¶: {A.shape}")
print(f"Bå½¢çŠ¶: {B.shape}")
print(f"ç»“æœå½¢çŠ¶: {result.shape}")  # (3, 4)

# è¿™å¯èƒ½ä¸æ˜¯ä½ æƒ³è¦çš„ç»“æœ
print("å¯èƒ½çš„é—®é¢˜ï¼šä½ ä»¥ä¸ºæ˜¯ (3,) + (4,)ï¼Œå®é™…ä¸Šæ˜¯ (3,1) + (1,4)")
```

### é™·é˜±2ï¼šå†…å­˜çˆ†ç‚¸
```python
# å°å¿ƒå¤§æ•°ç»„çš„å¹¿æ’­
big_array = np.random.randn(1000, 1000, 1)     # çº¦8MB
small_array = np.random.randn(1, 1, 1000)      # å¾ˆå°

# è¿™ä¼šåˆ›å»ºä¸€ä¸ª (1000, 1000, 1000) çš„æ•°ç»„ï¼Œçº¦8GBï¼
# result = big_array + small_array  # å±é™©ï¼

print(f"å¤§æ•°ç»„: {big_array.shape}")
print(f"å°æ•°ç»„: {small_array.shape}")
print(f"ç»“æœå°†æ˜¯: (1000, 1000, 1000) â‰ˆ 8GB")
```

### è§£å†³æ–¹æ¡ˆï¼šæ˜ç¡®å½¢çŠ¶æ£€æŸ¥
```python
def safe_broadcast_add(a, b, max_result_size=1e9):
    """å®‰å…¨çš„å¹¿æ’­åŠ æ³•ï¼Œé¿å…å†…å­˜çˆ†ç‚¸"""
    # è®¡ç®—ç»“æœå½¢çŠ¶
    result_shape = np.broadcast_shapes(a.shape, b.shape)
    result_size = np.prod(result_shape)
    
    if result_size > max_result_size:
        raise ValueError(f"ç»“æœæ•°ç»„å¤ªå¤§: {result_shape}, "
                        f"å¤§å°: {result_size:.0f} å…ƒç´ ")
    
    return a + b

# æµ‹è¯•
try:
    A = np.random.randn(1000, 1)
    B = np.random.randn(1, 1000)
    result = safe_broadcast_add(A, B, max_result_size=1e6)
except ValueError as e:
    print(f"æ•è·é”™è¯¯: {e}")
```

---

## ğŸ”§ å¹¿æ’­æ€§èƒ½ä¼˜åŒ–

### 1. é¿å…ä¸å¿…è¦çš„å¤åˆ¶
```python
import time

# å¤§æ•°ç»„
large_array = np.random.randn(1000, 1000)
small_array = np.random.randn(1000, 1)

# æ–¹æ³•1ï¼šæ˜¾å¼æ‰©å±•ï¼ˆæ…¢ï¼Œæ¶ˆè€—å†…å­˜ï¼‰
start = time.time()
expanded = np.tile(small_array, (1, 1000))
result1 = large_array + expanded
time1 = time.time() - start

# æ–¹æ³•2ï¼šä½¿ç”¨å¹¿æ’­ï¼ˆå¿«ï¼ŒèŠ‚çœå†…å­˜ï¼‰
start = time.time()
result2 = large_array + small_array
time2 = time.time() - start

print(f"æ˜¾å¼æ‰©å±•æ—¶é—´: {time1:.4f}ç§’")
print(f"å¹¿æ’­æ—¶é—´: {time2:.4f}ç§’")
print(f"é€Ÿåº¦æå‡: {time1/time2:.1f}å€")
print(f"ç»“æœç›¸åŒ: {np.allclose(result1, result2)}")
```

### 2. åˆç†å®‰æ’è¿ç®—é¡ºåº
```python
# é¿å…åˆ›å»ºå¤§çš„ä¸­é—´æ•°ç»„
A = np.random.randn(1000, 1000)
b = np.random.randn(1000, 1)
c = np.random.randn(1, 1000)

# ä¸å¥½ï¼šåˆ›å»ºå¤§çš„ä¸­é—´æ•°ç»„
# temp = b * c  # è¿™ä¼šåˆ›å»º (1000, 1000) çš„æ•°ç»„
# result = A + temp

# å¥½ï¼šåˆ©ç”¨è¿ç®—çš„ç»“åˆå¾‹
result = A + (b * c)  # å¹¿æ’­åœ¨è¿ç®—è¿‡ç¨‹ä¸­è¿›è¡Œ

print("ä¼˜åŒ–ï¼šåˆ©ç”¨è¿ç®—ç»“åˆå¾‹é¿å…å¤§çš„ä¸­é—´æ•°ç»„")
```

---

## ğŸ¯ å®æˆ˜æ¡ˆä¾‹

### æ¡ˆä¾‹1ï¼šæ•°æ®å¢å¼º
```python
def augment_data(images, rotation_angles, scale_factors):
    """
    å›¾åƒæ•°æ®å¢å¼ºç¤ºä¾‹
    images: (N, H, W, C)
    rotation_angles: (N,) æˆ– (1,)
    scale_factors: (N,) æˆ– (1,)
    """
    N, H, W, C = images.shape
    
    # åˆ›å»ºåæ ‡ç½‘æ ¼
    y, x = np.mgrid[0:H, 0:W]
    coords = np.stack([x, y], axis=-1)  # (H, W, 2)
    
    # ä¸­å¿ƒç‚¹
    center = np.array([W//2, H//2])
    
    # å°†åæ ‡ç›¸å¯¹äºä¸­å¿ƒ
    centered_coords = coords - center  # å¹¿æ’­ï¼š(H, W, 2) - (2,)
    
    # åº”ç”¨æ—‹è½¬å’Œç¼©æ”¾ï¼ˆè¿™é‡Œç®€åŒ–å¤„ç†ï¼‰
    cos_theta = np.cos(rotation_angles)
    sin_theta = np.sin(rotation_angles)
    
    # æ—‹è½¬çŸ©é˜µ (N, 2, 2) æˆ–å¹¿æ’­å…¼å®¹å½¢çŠ¶
    rotation_matrix = np.array([[cos_theta, -sin_theta],
                               [sin_theta, cos_theta]])
    
    # åº”ç”¨å˜æ¢ï¼ˆè¿™é‡Œå±•ç¤ºå¹¿æ’­æ¦‚å¿µï¼‰
    print(f"å›¾åƒå½¢çŠ¶: {images.shape}")
    print(f"æ—‹è½¬è§’åº¦å½¢çŠ¶: {rotation_angles.shape}")
    print(f"ç¼©æ”¾å› å­å½¢çŠ¶: {scale_factors.shape}")
    
    return "å¢å¼ºåçš„å›¾åƒ"  # ç®€åŒ–è¿”å›

# æµ‹è¯•
images = np.random.randint(0, 256, (10, 64, 64, 3))
angles = np.random.uniform(0, 2*np.pi, 10)
scales = np.random.uniform(0.8, 1.2, 1)  # æ‰€æœ‰å›¾åƒç›¸åŒç¼©æ”¾

result = augment_data(images, angles, scales)
```

### æ¡ˆä¾‹2ï¼šé‡‘èé£é™©è®¡ç®—
```python
def calculate_portfolio_risk(returns, weights, correlation_matrix):
    """
    è®¡ç®—æŠ•èµ„ç»„åˆé£é™©
    returns: (T, N) - Tä¸ªæ—¶é—´ç‚¹ï¼ŒNä¸ªèµ„äº§çš„æ”¶ç›Šç‡
    weights: (N,) - èµ„äº§æƒé‡
    correlation_matrix: (N, N) - ç›¸å…³ç³»æ•°çŸ©é˜µ
    """
    T, N = returns.shape
    
    # è®¡ç®—æ¯ä¸ªèµ„äº§çš„æ³¢åŠ¨ç‡
    volatilities = returns.std(axis=0)  # (N,)
    
    # åæ–¹å·®çŸ©é˜µ
    # volatilities[:, np.newaxis] * volatilities åˆ©ç”¨å¹¿æ’­
    covariance_matrix = (volatilities[:, np.newaxis] * 
                        correlation_matrix * 
                        volatilities)  # (N, 1) * (N, N) * (N,) -> (N, N)
    
    # æŠ•èµ„ç»„åˆæ–¹å·®ï¼ˆä½¿ç”¨å¹¿æ’­ï¼‰
    portfolio_variance = weights @ covariance_matrix @ weights
    portfolio_volatility = np.sqrt(portfolio_variance)
    
    print(f"æ”¶ç›Šç‡æ•°æ®å½¢çŠ¶: {returns.shape}")
    print(f"æƒé‡å½¢çŠ¶: {weights.shape}")
    print(f"ç›¸å…³çŸ©é˜µå½¢çŠ¶: {correlation_matrix.shape}")
    print(f"åæ–¹å·®çŸ©é˜µå½¢çŠ¶: {covariance_matrix.shape}")
    print(f"æŠ•èµ„ç»„åˆæ³¢åŠ¨ç‡: {portfolio_volatility:.4f}")
    
    return portfolio_volatility

# ç¤ºä¾‹æ•°æ®
np.random.seed(42)
returns = np.random.randn(252, 5)  # 1å¹´æ—¥æ”¶ç›Šç‡ï¼Œ5ä¸ªèµ„äº§
weights = np.array([0.2, 0.2, 0.2, 0.2, 0.2])  # ç­‰æƒé‡
correlation = np.random.rand(5, 5)
correlation = (correlation + correlation.T) / 2  # å¯¹ç§°åŒ–
np.fill_diagonal(correlation, 1)  # å¯¹è§’çº¿ä¸º1

risk = calculate_portfolio_risk(returns, weights, correlation)
```

---

## ğŸ“š æ€»ç»“ä¸å»ºè®®

### å¹¿æ’­çš„å¨åŠ›
1. **å†…å­˜æ•ˆç‡**ï¼šé¿å…ä¸å¿…è¦çš„æ•°ç»„å¤åˆ¶
2. **è®¡ç®—æ•ˆç‡**ï¼šåº•å±‚ä¼˜åŒ–çš„Cä»£ç æ‰§è¡Œ
3. **ä»£ç ç®€æ´**ï¼šå‡å°‘æ˜¾å¼å¾ªç¯
4. **è¡¨è¾¾åŠ›å¼º**ï¼šæ›´æ¥è¿‘æ•°å­¦è¡¨è¾¾å¼

### æŒæ¡è¦ç‚¹
1. **ç†è§£è§„åˆ™**ï¼šä»å³åˆ°å·¦æ¯”è¾ƒç»´åº¦
2. **å®è·µè¿ç”¨**ï¼šå¤šåšç»ƒä¹ ï¼ŒåŸ¹å…»ç›´è§‰
3. **æ³¨æ„é™·é˜±**ï¼šå°å¿ƒå†…å­˜çˆ†ç‚¸å’Œæ„å¤–ç»“æœ
4. **æ€§èƒ½ä¼˜åŒ–**ï¼šåˆç†å®‰æ’è¿ç®—é¡ºåº

### å­¦ä¹ å»ºè®®
1. **å¯è§†åŒ–ç»ƒä¹ **ï¼šç”»å›¾ç†è§£å½¢çŠ¶å˜åŒ–
2. **å®é™…é¡¹ç›®**ï¼šåœ¨çœŸå®æ•°æ®ä¸Šåº”ç”¨
3. **é”™è¯¯è°ƒè¯•**ï¼šç†è§£å¸¸è§é”™è¯¯ä¿¡æ¯
4. **æ€§èƒ½æµ‹è¯•**ï¼šæ¯”è¾ƒä¸åŒå®ç°çš„æ•ˆç‡

### ä¸‹ä¸€æ­¥å­¦ä¹ 
- é«˜çº§ç´¢å¼•ä¸å¹¿æ’­ç»“åˆ
- åœ¨æ·±åº¦å­¦ä¹ æ¡†æ¶ä¸­çš„åº”ç”¨
- å†…å­˜å¸ƒå±€å’Œæ€§èƒ½ä¼˜åŒ–
- è‡ªå®šä¹‰ufuncå‡½æ•°

---

**ğŸŒŸ è®°ä½ï¼šå¹¿æ’­æœºåˆ¶æ˜¯NumPyçš„è¶…çº§åŠ›é‡ï¼ŒæŒæ¡å®ƒè®©ä½ çš„ä»£ç æ—¢ä¼˜é›…åˆé«˜æ•ˆï¼** 