"""
æ‰‹å†™çº¿æ€§å›å½’æŒ‘æˆ˜ - æ–­ç½‘ç»ƒä¹ ï¼ğŸ”¥
ç›®æ ‡ï¼šä»é›¶å®ç°çº¿æ€§å›å½’ç®—æ³•
æ—¶é—´ï¼š40åˆ†é’Ÿ
"""

import numpy as np
import matplotlib.pyplot as plt

print("ğŸ”¥ æ‰‹å†™çº¿æ€§å›å½’æŒ‘æˆ˜ - æ–­ç½‘ç»ƒä¹ ")
print("="*50)
print("âš ï¸  é‡è¦ï¼šå°½é‡ä¸æŸ¥èµ„æ–™ï¼Œç†è§£æ¯ä¸ªæ­¥éª¤ï¼")
print("ğŸ’¡ æ ¸å¿ƒæ€æƒ³ï¼šæ‰¾åˆ°æœ€ä½³çš„ç›´çº¿æ‹Ÿåˆæ•°æ®")

# ===== ç¬¬1å…³ï¼šç†è§£çº¿æ€§å›å½’ =====
print("\nğŸ¯ ç¬¬1å…³ï¼šç†è§£çº¿æ€§å›å½’")
print("çº¿æ€§å›å½’å…¬å¼ï¼šy = w*x + b")
print("ç›®æ ‡ï¼šæ‰¾åˆ°æœ€ä½³çš„wï¼ˆæ–œç‡ï¼‰å’Œbï¼ˆæˆªè·ï¼‰")

# åˆ›å»ºç¤ºä¾‹æ•°æ®
np.random.seed(42)
X = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])
y = np.array([2, 4, 6, 8, 10, 12, 14, 16, 18, 20]) + np.random.randn(10) * 2

print(f"æ•°æ®ï¼šX = {X}")
print(f"æ•°æ®ï¼šy = {y}")

# ä»»åŠ¡1.1ï¼šå¯è§†åŒ–æ•°æ®
print("\nğŸ“ ä»»åŠ¡1.1ï¼šå¯è§†åŒ–æ•°æ®")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# plt.figure(figsize=(10, 6))
# plt.scatter(X, y, alpha=0.6)
# plt.xlabel('X')
# plt.ylabel('y')
# plt.title('åŸå§‹æ•°æ®')
# plt.show()

# ===== ç¬¬2å…³ï¼šæœ€å°äºŒä¹˜æ³•å…¬å¼ =====
print("\nğŸ¯ ç¬¬2å…³ï¼šæœ€å°äºŒä¹˜æ³•å…¬å¼")
print("æœ€å°äºŒä¹˜æ³•ï¼šé€šè¿‡æœ€å°åŒ–å¹³æ–¹è¯¯å·®æ¥æ‰¾åˆ°æœ€ä½³å‚æ•°")
print("å…¬å¼ï¼š")
print("w = (Î£(x*y) - n*mean(x)*mean(y)) / (Î£(xÂ²) - n*mean(x)Â²)")
print("b = mean(y) - w*mean(x)")

# ä»»åŠ¡2.1ï¼šè®¡ç®—å‡å€¼
print("\nğŸ“ ä»»åŠ¡2.1ï¼šè®¡ç®—Xå’Œyçš„å‡å€¼")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# mean_x = 
# mean_y = 
# print(f"Xçš„å‡å€¼: {mean_x}")
# print(f"yçš„å‡å€¼: {mean_y}")

# ä»»åŠ¡2.2ï¼šè®¡ç®—éœ€è¦çš„ç»Ÿè®¡é‡
print("\nğŸ“ ä»»åŠ¡2.2ï¼šè®¡ç®—ç»Ÿè®¡é‡")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# sum_xy = np.sum(X * y)
# sum_x_squared = np.sum(X ** 2)
# n = len(X)
# print(f"Î£(x*y) = {sum_xy}")
# print(f"Î£(xÂ²) = {sum_x_squared}")
# print(f"æ ·æœ¬æ•°é‡ n = {n}")

# ä»»åŠ¡2.3ï¼šè®¡ç®—wå’Œb
print("\nğŸ“ ä»»åŠ¡2.3ï¼šä½¿ç”¨æœ€å°äºŒä¹˜æ³•è®¡ç®—wå’Œb")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# w = (sum_xy - n * mean_x * mean_y) / (sum_x_squared - n * mean_x**2)
# b = mean_y - w * mean_x
# print(f"æ–œç‡ w = {w:.4f}")
# print(f"æˆªè· b = {b:.4f}")

# ===== ç¬¬3å…³ï¼šçŸ©é˜µæ–¹å¼è®¡ç®— =====
print("\nğŸ¯ ç¬¬3å…³ï¼šçŸ©é˜µæ–¹å¼è®¡ç®—")
print("çº¿æ€§å›å½’çš„çŸ©é˜µå½¢å¼ï¼šÎ¸ = (X^T * X)^(-1) * X^T * y")
print("å…¶ä¸­ Î¸ = [b, w]ï¼ŒX = [1, x] (å¢åŠ åç½®åˆ—)")

# ä»»åŠ¡3.1ï¼šæ„å»ºè®¾è®¡çŸ©é˜µ
print("\nğŸ“ ä»»åŠ¡3.1ï¼šæ„å»ºè®¾è®¡çŸ©é˜µ")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# X_matrix = np.column_stack((np.ones(len(X)), X))
# print(f"è®¾è®¡çŸ©é˜µ X_matrix å½¢çŠ¶: {X_matrix.shape}")
# print(f"å‰5è¡Œ:\n{X_matrix[:5]}")

# ä»»åŠ¡3.2ï¼šè®¡ç®—å‚æ•°
print("\nğŸ“ ä»»åŠ¡3.2ï¼šä½¿ç”¨çŸ©é˜µå…¬å¼è®¡ç®—å‚æ•°")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# theta = np.linalg.inv(X_matrix.T @ X_matrix) @ X_matrix.T @ y
# b_matrix = theta[0]
# w_matrix = theta[1]
# print(f"çŸ©é˜µæ–¹æ³•ï¼šb = {b_matrix:.4f}, w = {w_matrix:.4f}")

# ä»»åŠ¡3.3ï¼šéªŒè¯ç»“æœ
print("\nğŸ“ ä»»åŠ¡3.3ï¼šéªŒè¯ä¸¤ç§æ–¹æ³•çš„ç»“æœ")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# print(f"æœ€å°äºŒä¹˜æ³•ï¼šb = {b:.4f}, w = {w:.4f}")
# print(f"çŸ©é˜µæ–¹æ³•ï¼š  b = {b_matrix:.4f}, w = {w_matrix:.4f}")
# print(f"ç»“æœæ˜¯å¦ä¸€è‡´: {np.allclose([b, w], [b_matrix, w_matrix])}")

# ===== ç¬¬4å…³ï¼šé¢„æµ‹å’Œè¯„ä¼° =====
print("\nğŸ¯ ç¬¬4å…³ï¼šé¢„æµ‹å’Œè¯„ä¼°")

# ä»»åŠ¡4.1ï¼šè¿›è¡Œé¢„æµ‹
print("\nğŸ“ ä»»åŠ¡4.1ï¼šä½¿ç”¨æˆ‘ä»¬çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# y_pred = w * X + b
# print(f"é¢„æµ‹ç»“æœ: {y_pred}")

# ä»»åŠ¡4.2ï¼šè®¡ç®—å‡æ–¹è¯¯å·®
print("\nğŸ“ ä»»åŠ¡4.2ï¼šè®¡ç®—å‡æ–¹è¯¯å·®(MSE)")
print("MSE = (1/n) * Î£(y_true - y_pred)Â²")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# mse = np.mean((y - y_pred)**2)
# print(f"å‡æ–¹è¯¯å·®: {mse:.4f}")

# ä»»åŠ¡4.3ï¼šè®¡ç®—RÂ²åˆ†æ•°
print("\nğŸ“ ä»»åŠ¡4.3ï¼šè®¡ç®—RÂ²åˆ†æ•°")
print("RÂ² = 1 - (SS_res / SS_tot)")
print("SS_res = Î£(y_true - y_pred)Â²")
print("SS_tot = Î£(y_true - mean(y))Â²")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# ss_res = np.sum((y - y_pred)**2)
# ss_tot = np.sum((y - mean_y)**2)
# r2 = 1 - (ss_res / ss_tot)
# print(f"RÂ²åˆ†æ•°: {r2:.4f}")

# ===== ç¬¬5å…³ï¼šå¯è§†åŒ–ç»“æœ =====
print("\nğŸ¯ ç¬¬5å…³ï¼šå¯è§†åŒ–ç»“æœ")

# ä»»åŠ¡5.1ï¼šç»˜åˆ¶æ‹Ÿåˆçº¿
print("\nğŸ“ ä»»åŠ¡5.1ï¼šç»˜åˆ¶æ•°æ®å’Œæ‹Ÿåˆçº¿")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# plt.figure(figsize=(10, 6))
# plt.scatter(X, y, alpha=0.6, label='çœŸå®æ•°æ®')
# plt.plot(X, y_pred, 'r-', label=f'æ‹Ÿåˆçº¿: y = {w:.2f}x + {b:.2f}')
# plt.xlabel('X')
# plt.ylabel('y')
# plt.title('æ‰‹å†™çº¿æ€§å›å½’ç»“æœ')
# plt.legend()
# plt.show()

# ä»»åŠ¡5.2ï¼šç»˜åˆ¶æ®‹å·®å›¾
print("\nğŸ“ ä»»åŠ¡5.2ï¼šç»˜åˆ¶æ®‹å·®å›¾")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# residuals = y - y_pred
# plt.figure(figsize=(10, 6))
# plt.scatter(y_pred, residuals, alpha=0.6)
# plt.axhline(y=0, color='r', linestyle='--')
# plt.xlabel('é¢„æµ‹å€¼')
# plt.ylabel('æ®‹å·®')
# plt.title('æ®‹å·®å›¾')
# plt.show()

# ===== ç¬¬6å…³ï¼šæ¢¯åº¦ä¸‹é™å®ç° =====
print("\nğŸ¯ ç¬¬6å…³ï¼šæ¢¯åº¦ä¸‹é™å®ç°ï¼ˆæŒ‘æˆ˜ï¼‰")
print("ä½¿ç”¨æ¢¯åº¦ä¸‹é™ä¼˜åŒ–ç®—æ³•æ¥æ‰¾åˆ°æœ€ä½³å‚æ•°")

# ä»»åŠ¡6.1ï¼šå®ç°æ¢¯åº¦ä¸‹é™
print("\nğŸ“ ä»»åŠ¡6.1ï¼šå®ç°æ¢¯åº¦ä¸‹é™ç®—æ³•")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# def gradient_descent(X, y, lr=0.01, epochs=1000):
#     # åˆå§‹åŒ–å‚æ•°
#     w = 0.0
#     b = 0.0
#     n = len(X)
#     
#     for epoch in range(epochs):
#         # é¢„æµ‹
#         y_pred = w * X + b
#         
#         # è®¡ç®—æŸå¤±å‡½æ•°çš„æ¢¯åº¦
#         dw = (-2/n) * np.sum(X * (y - y_pred))
#         db = (-2/n) * np.sum(y - y_pred)
#         
#         # æ›´æ–°å‚æ•°
#         w = w - lr * dw
#         b = b - lr * db
#         
#         # æ¯100è½®æ‰“å°ä¸€æ¬¡æŸå¤±
#         if epoch % 100 == 0:
#             loss = np.mean((y - y_pred)**2)
#             print(f"Epoch {epoch}, Loss: {loss:.4f}")
#     
#     return w, b

# ä»»åŠ¡6.2ï¼šè¿è¡Œæ¢¯åº¦ä¸‹é™
print("\nğŸ“ ä»»åŠ¡6.2ï¼šè¿è¡Œæ¢¯åº¦ä¸‹é™ç®—æ³•")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# w_gd, b_gd = gradient_descent(X, y)
# print(f"æ¢¯åº¦ä¸‹é™ç»“æœï¼šw = {w_gd:.4f}, b = {b_gd:.4f}")

# ä»»åŠ¡6.3ï¼šå¯¹æ¯”ä¸‰ç§æ–¹æ³•
print("\nğŸ“ ä»»åŠ¡6.3ï¼šå¯¹æ¯”ä¸‰ç§æ–¹æ³•çš„ç»“æœ")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# print("å‚æ•°å¯¹æ¯”ï¼š")
# print(f"æœ€å°äºŒä¹˜æ³•ï¼šw = {w:.4f}, b = {b:.4f}")
# print(f"çŸ©é˜µæ–¹æ³•ï¼š  w = {w_matrix:.4f}, b = {b_matrix:.4f}")
# print(f"æ¢¯åº¦ä¸‹é™ï¼š  w = {w_gd:.4f}, b = {b_gd:.4f}")

# ===== ç¬¬7å…³ï¼šä¸sklearnå¯¹æ¯” =====
print("\nğŸ¯ ç¬¬7å…³ï¼šä¸sklearnå¯¹æ¯”")

# ä»»åŠ¡7.1ï¼šä½¿ç”¨sklearnéªŒè¯
print("\nğŸ“ ä»»åŠ¡7.1ï¼šä½¿ç”¨sklearnéªŒè¯æˆ‘ä»¬çš„ç»“æœ")
print("ä½ çš„ä»£ç ï¼š")
# åœ¨è¿™é‡Œå†™ä»£ç ï¼š
# from sklearn.linear_model import LinearRegression
# sklearn_model = LinearRegression()
# sklearn_model.fit(X.reshape(-1, 1), y)
# print(f"sklearnç»“æœï¼šw = {sklearn_model.coef_[0]:.4f}, b = {sklearn_model.intercept_:.4f}")

# ===== è‡ªæˆ‘æ£€æŸ¥ =====
print("\n" + "="*50)
print("ğŸ å®Œæˆç»ƒä¹ åï¼Œè¯·æ£€æŸ¥ï¼š")
print("1. ä½ ç†è§£æœ€å°äºŒä¹˜æ³•çš„åŸç†äº†å—ï¼Ÿ")
print("2. ä½ èƒ½è§£é‡Šä¸ºä»€ä¹ˆä¸‰ç§æ–¹æ³•ç»“æœç›¸åŒå—ï¼Ÿ")
print("3. ä½ çŸ¥é“ä½•æ—¶ä½¿ç”¨æ¢¯åº¦ä¸‹é™å—ï¼Ÿ")
print("4. ä½ èƒ½ä»é›¶å®ç°çº¿æ€§å›å½’äº†å—ï¼Ÿ")
print("\nğŸ’¡ è®°å½•ä¸‹å›°éš¾çš„åœ°æ–¹ï¼Œé‡ç‚¹å¤ä¹ ï¼")

# ===== æç¤ºåŒºåŸŸ =====
print("\n" + "="*50)
print("ğŸ“– æç¤ºåŒºåŸŸ (å®åœ¨ä¸ä¼šæ—¶å†çœ‹)")
print("- å‡å€¼ï¼šnp.mean(array)")
print("- çŸ©é˜µä¹˜æ³•ï¼šA @ B")
print("- çŸ©é˜µè½¬ç½®ï¼šA.T")
print("- çŸ©é˜µæ±‚é€†ï¼šnp.linalg.inv(A)")
print("- æ•°ç»„å½¢çŠ¶ï¼šarray.reshape(-1, 1)")
print("="*50) 