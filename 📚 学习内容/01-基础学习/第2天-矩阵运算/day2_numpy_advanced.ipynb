{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 第二天：NumPy进阶操作\n",
    "\n",
    "## 今日学习目标\n",
    "1. 掌握NumPy数组的高级索引和切片\n",
    "2. 理解广播机制（Broadcasting）\n",
    "3. 学习数组的形状操作\n",
    "4. 实现矩阵运算函数库\n",
    "5. 实现简单的PCA算法\n",
    "6. 解决中文字体显示问题\n",
    "\n",
    "## 预计学习时间：5-6小时\n",
    "- 理论学习：2小时\n",
    "- 编程实践：3-4小时\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 解决中文字体显示问题\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"NumPy版本:\", np.__version__)\n",
    "print(\"Matplotlib版本:\", matplotlib.__version__)\n",
    "print(\"第二天学习开始！🚀\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. 数组索引和切片进阶\n",
    "\n",
    "### 学习要点：\n",
    "- 基本索引：`arr[0]`, `arr[:, 0]`, `arr[1, 2]`\n",
    "- 布尔索引：`arr[arr > 10]`\n",
    "- 花式索引：`arr[[0, 2, 3]]`\n",
    "- 条件索引：`arr[arr % 2 == 0]`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建测试数组\n",
    "arr = np.arange(20).reshape(4, 5)\n",
    "print(\"原始数组:\")\n",
    "print(arr)\n",
    "print(f\"数组形状: {arr.shape}\")\n",
    "print(f\"数组类型: {arr.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本索引示例\n",
    "print(\"\\n=== 基本索引 ===\")\n",
    "print(f\"第一行: {arr[0]}\")\n",
    "print(f\"第一列: {arr[:, 0]}\")\n",
    "print(f\"第二行第三列: {arr[1, 2]}\")\n",
    "print(f\"前两行: \\n{arr[:2]}\")\n",
    "print(f\"后两列: \\n{arr[:, -2:]}\")\n",
    "print(f\"每隔一行: \\n{arr[::2]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习任务：请在下面完成\n",
    "print(\"\\n=== 练习任务 ===\")\n",
    "# 1. 获取第二行的所有元素\n",
    "second_row = arr[1]\n",
    "print(f\"第二行: {second_row}\")\n",
    "\n",
    "# 2. 获取第三列的所有元素  \n",
    "third_col = arr[:, 2]\n",
    "print(f\"第三列: {third_col}\")\n",
    "\n",
    "# 3. 获取前两行，后三列的子数组\n",
    "sub_array = arr[:2, -3:]\n",
    "print(f\"前两行后三列: \\n{sub_array}\")\n",
    "\n",
    "# 4. 获取所有大于10的元素\n",
    "greater_than_10 = arr[arr > 10]\n",
    "print(f\"大于10的元素: {greater_than_10}\")\n",
    "\n",
    "# 5. 获取所有偶数\n",
    "even_numbers = arr[arr % 2 == 0]\n",
    "print(f\"偶数: {even_numbers}\")\n",
    "\n",
    "# 6. 花式索引：获取第0行、第2行、第3行\n",
    "fancy_index = arr[[0, 2, 3]]\n",
    "print(f\"第0,2,3行: \\n{fancy_index}\")\n",
    "\n",
    "print(\"\\n✅ 索引和切片练习完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. 广播机制（Broadcasting）\n",
    "\n",
    "### 什么是广播？\n",
    "广播是NumPy中一个重要概念，它允许不同形状的数组之间进行运算。\n",
    "\n",
    "### 广播规则：\n",
    "1. 从最右边的维度开始比较\n",
    "2. 如果两个数组的维度不相等，较小的数组会在左边补1\n",
    "3. 如果某个维度大小为1，那么该维度会被\"拉伸\"以匹配另一个数组\n",
    "4. 如果某个维度大小不为1且不相等，则无法广播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 广播机制演示\n",
    "print(\"=== 广播机制演示 ===\")\n",
    "\n",
    "# 示例1：矩阵与向量\n",
    "matrix_a = np.array([[1, 2, 3],\n",
    "                     [4, 5, 6]])\n",
    "vector_b = np.array([10, 20, 30])\n",
    "\n",
    "print(f\"矩阵A形状: {matrix_a.shape}\")\n",
    "print(f\"矩阵A:\\n{matrix_a}\")\n",
    "print(f\"向量B形状: {vector_b.shape}\")\n",
    "print(f\"向量B: {vector_b}\")\n",
    "\n",
    "# 广播相加\n",
    "result_add = matrix_a + vector_b\n",
    "print(f\"\\n广播相加结果:\\n{result_add}\")\n",
    "\n",
    "# 广播相乘\n",
    "result_mul = matrix_a * vector_b\n",
    "print(f\"\\n广播相乘结果:\\n{result_mul}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例2：更复杂的广播\n",
    "print(\"\\n=== 复杂广播示例 ===\")\n",
    "matrix_c = np.array([[1],\n",
    "                     [2],\n",
    "                     [3]])\n",
    "vector_d = np.array([10, 20, 30, 40])\n",
    "\n",
    "print(f\"矩阵C形状: {matrix_c.shape}\")\n",
    "print(f\"矩阵C:\\n{matrix_c}\")\n",
    "print(f\"向量D形状: {vector_d.shape}\")\n",
    "print(f\"向量D: {vector_d}\")\n",
    "\n",
    "# 广播相乘\n",
    "result_complex = matrix_c * vector_d\n",
    "print(f\"\\n复杂广播结果:\\n{result_complex}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 示例3：广播在实际应用中的例子\n",
    "print(\"\\n=== 实际应用示例 ===\")\n",
    "# 假设我们有一个图像数据（简化版）\n",
    "image = np.random.randint(0, 256, (3, 4, 4))  # 3通道，4x4图像\n",
    "print(f\"图像数据形状: {image.shape}\")\n",
    "\n",
    "# 我们想要对每个通道应用不同的权重\n",
    "weights = np.array([0.3, 0.6, 0.1])  # RGB权重\n",
    "print(f\"权重形状: {weights.shape}\")\n",
    "\n",
    "# 使用广播应用权重\n",
    "weighted_image = image * weights[:, np.newaxis, np.newaxis]\n",
    "print(f\"加权后图像形状: {weighted_image.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习任务\n",
    "print(\"\\n=== 练习任务 ===\")\n",
    "# 1. 创建一个5x3的矩阵和一个长度为3的向量，进行广播相加\n",
    "matrix1 = np.arange(15).reshape(5,3)\n",
    "print(f\"5x3矩阵:\\n{matrix1}\")\n",
    "vector1 = np.arange(3)\n",
    "print(f\"长度为3的向量:\\n{vector1}\")\n",
    "print(f\"5x3矩阵 和长度为3的向量 广播相加:\\n{matrix1 + vector1}\")\n",
    "\n",
    "# 2. 创建一个3x1的矩阵和一个长度为4的向量，进行广播相乘\n",
    "matrix2 = np.arange(3).reshape(3,1)\n",
    "vector2 = np.arange(4)\n",
    "print(f\"3x1矩阵:\\n{matrix2}\")\n",
    "print(f\"长度为4的向量:\\n{vector2}\")\n",
    "print(f\"3x1矩阵 和长度为4的向量 广播相乘:\\n{matrix2 * vector2}\")\n",
    "\n",
    "print(\"\\n✅ 广播机制练习完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. 数组形状操作\n",
    "\n",
    "### 主要函数：\n",
    "- `reshape()`: 重塑数组形状\n",
    "- `transpose()` 或 `.T`: 转置\n",
    "- `flatten()`: 展平数组\n",
    "- `ravel()`: 展平数组（返回视图）\n",
    "- `vstack()` 和 `hstack()`: 数组拼接\n",
    "- `concatenate()`: 通用拼接函数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数组形状操作演示\n",
    "print(\"=== 数组形状操作 ===\")\n",
    "\n",
    "# 创建原始数组\n",
    "original = np.arange(12)\n",
    "print(f\"原始数组: {original}\")\n",
    "print(f\"原始形状: {original.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 重塑形状\n",
    "reshaped_2d = original.reshape(3, 4)\n",
    "print(f\"\\n重塑为3x4:\\n{reshaped_2d}\")\n",
    "\n",
    "reshaped_3d = original.reshape(2, 2, 3)\n",
    "print(f\"\\n重塑为2x2x3:\\n{reshaped_3d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 转置\n",
    "transposed = reshaped_2d.T\n",
    "print(f\"\\n转置后:\\n{transposed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 展平\n",
    "flattened = reshaped_2d.flatten()\n",
    "print(f\"\\n展平后: {flattened}\")\n",
    "\n",
    "# ravel和flatten的区别\n",
    "raveled = reshaped_2d.ravel()\n",
    "print(f\"ravel后: {raveled}\")\n",
    "\n",
    "# 修改ravel的结果会影响原数组\n",
    "raveled[0] = 999\n",
    "print(f\"修改ravel后，原数组:\\n{reshaped_2d}\")\n",
    "\n",
    "# 重新创建数组用于后续演示\n",
    "arr1 = np.array([[1, 2], [3, 4]])\n",
    "arr2 = np.array([[5, 6], [7, 8]])\n",
    "print(f\"\\n数组1:\\n{arr1}\")\n",
    "print(f\"数组2:\\n{arr2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 垂直拼接\n",
    "v_concat = np.vstack((arr1, arr2))\n",
    "print(f\"\\n垂直拼接:\\n{v_concat}\")\n",
    "\n",
    "# 5. 水平拼接\n",
    "h_concat = np.hstack((arr1, arr2))\n",
    "print(f\"\\n水平拼接:\\n{h_concat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 通用拼接函数\n",
    "concat_axis0 = np.concatenate((arr1, arr2), axis=0)\n",
    "print(f\"\\n沿axis=0拼接:\\n{concat_axis0}\")\n",
    "\n",
    "concat_axis1 = np.concatenate((arr1, arr2), axis=1)\n",
    "print(f\"\\n沿axis=1拼接:\\n{concat_axis1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 添加维度\n",
    "print(f\"\\n=== 添加维度 ===\")\n",
    "arr_1d = np.array([1, 2, 3])\n",
    "print(f\"1D数组: {arr_1d}, 形状: {arr_1d.shape}\")\n",
    "\n",
    "# 添加新轴\n",
    "arr_2d_col = arr_1d[:, np.newaxis]\n",
    "print(f\"列向量:\\n{arr_2d_col}, 形状: {arr_2d_col.shape}\")\n",
    "\n",
    "arr_2d_row = arr_1d[np.newaxis, :]\n",
    "print(f\"行向量:\\n{arr_2d_row}, 形状: {arr_2d_row.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 删除维度\n",
    "print(f\"\\n=== 删除维度 ===\")\n",
    "arr_with_single_dim = np.array([[[1, 2, 3]]])\n",
    "print(f\"原数组形状: {arr_with_single_dim.shape}\")\n",
    "\n",
    "squeezed = np.squeeze(arr_with_single_dim)\n",
    "print(f\"压缩后形状: {squeezed.shape}\")\n",
    "print(f\"压缩后数组: {squeezed}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 练习任务\n",
    "print(\"\\n=== 练习任务 ===\")\n",
    "# 1. 创建一个1到24的数组，重塑为2x3x4\n",
    "matrix3 = np.arange(1,25).reshape(2,3,4)\n",
    "print(f\"练习1 - 2x3x4数组:\\n{matrix3}\")\n",
    "\n",
    "# 2. 创建两个2x3的矩阵，分别进行垂直和水平拼接\n",
    "matrix4 = np.arange(6).reshape(2,3)\n",
    "matrix5 = np.arange(6,12).reshape(2,3)\n",
    "print(f\"练习2 - 垂直拼接:\\n{np.vstack((matrix4,matrix5))}\")\n",
    "print(f\"练习2 - 水平拼接:\\n{np.hstack((matrix4,matrix5))}\")\n",
    "\n",
    "print(\"\\n✅ 数组形状操作练习完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. 统计和聚合函数\n",
    "\n",
    "### 常用统计函数：\n",
    "- `np.sum()`: 求和\n",
    "- `np.mean()`: 平均值\n",
    "- `np.median()`: 中位数\n",
    "- `np.std()`: 标准差\n",
    "- `np.var()`: 方差\n",
    "- `np.max()`, `np.min()`: 最大值和最小值\n",
    "- `np.argmax()`, `np.argmin()`: 最大值和最小值的索引\n",
    "- `np.percentile()`: 百分位数\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 统计和聚合函数 ===\n",
      "测试数据:\n",
      "[[52 93 15 72]\n",
      " [61 21 83 87]\n",
      " [75 75 88 24]\n",
      " [ 3 22 53  2]\n",
      " [88 30 38  2]]\n",
      "数据形状: (5, 4)\n",
      "\n",
      "=== 基本统计 ===\n",
      "总和: 984\n",
      "平均值: 49.20\n",
      "中位数: 52.5\n",
      "最大值: 93\n",
      "最小值: 2\n",
      "标准差: 31.57\n",
      "方差: 996.86\n",
      "\n",
      "=== 位置信息 ===\n",
      "最大值位置: 1\n",
      "最小值位置: 15\n",
      "最大值位置(行,列): (np.int64(0), np.int64(1))\n",
      "最小值位置(行,列): (np.int64(3), np.int64(3))\n",
      "\n",
      "=== 按轴统计 ===\n",
      "按行求和 (axis=1): [232 252 262  80 158]\n",
      "按列求和 (axis=0): [279 241 277 187]\n",
      "按行求平均 (axis=1): [58.  63.  65.5 20.  39.5]\n",
      "按列求平均 (axis=0): [55.8 48.2 55.4 37.4]\n",
      "\n",
      "=== 累积统计 ===\n",
      "累积和: [ 52 145 160 232 293 314 397 484 559 634 722 746 749 771 824 826 914 944\n",
      " 982 984]\n",
      "累积乘积: [                  52                 4836                72540\n",
      "              5222880            318595680           6690509280\n",
      "         555312270240       48312167510880     3623412563316000\n",
      "   271755942248700000  5467778844176048384  2099483744258299904\n",
      "  6298451232774899712 -9008025468628619264  2189996079131521024\n",
      "  4379992158263042048 -1942315620752883712 -2929236401457856512\n",
      "  -630518813141237760 -1261037626282475520]\n",
      "\n",
      "=== 百分位数 ===\n",
      "25%分位数: 21.75\n",
      "50%分位数: 52.5\n",
      "75%分位数: 77.0\n",
      "\n",
      "=== 条件统计 ===\n",
      "大于50的元素数量: 11\n",
      "大于50的元素比例: 55.00%\n",
      "每行中大于50的元素数量: [3 3 3 1 1]\n",
      "\n",
      "=== 自定义统计 ===\n",
      "数据范围: 91\n",
      "每行的范围: [np.int64(78), np.int64(66), np.int64(64), np.int64(51), np.int64(86)]\n",
      "\n",
      "=== 练习任务 ===\n",
      "均值: 47.69605439407796\n",
      "标准差: 13.454074036396353\n",
      "最大值: 78.29278851815795\n",
      "最小值: 10.703823438653835\n",
      "复杂数据:\n",
      "[[0.96244729 0.2517823  0.49724851]\n",
      " [0.30087831 0.28484049 0.03688695]]\n",
      "复杂数据形状: (2, 3)\n",
      "复杂数据按 axis=0 的平均值: [0.6316628  0.2683114  0.26706773]\n",
      "\n",
      "✅ 统计和聚合函数练习完成！\n"
     ]
    }
   ],
   "source": [
    "# 统计和聚合函数演示\n",
    "print(\"=== 统计和聚合函数 ===\")\n",
    "\n",
    "# 创建测试数据\n",
    "np.random.seed(42)\n",
    "data = np.random.randint(1, 100, size=(5, 4))\n",
    "print(f\"测试数据:\\n{data}\")\n",
    "print(f\"数据形状: {data.shape}\")\n",
    "\n",
    "# 基本统计\n",
    "print(f\"\\n=== 基本统计 ===\")\n",
    "print(f\"总和: {np.sum(data)}\")\n",
    "print(f\"平均值: {np.mean(data):.2f}\")\n",
    "print(f\"中位数: {np.median(data)}\")\n",
    "print(f\"最大值: {np.max(data)}\")\n",
    "print(f\"最小值: {np.min(data)}\")\n",
    "print(f\"标准差: {np.std(data):.2f}\")\n",
    "print(f\"方差: {np.var(data):.2f}\")\n",
    "\n",
    "# 最大值和最小值的位置\n",
    "print(f\"\\n=== 位置信息 ===\")\n",
    "print(f\"最大值位置: {np.argmax(data)}\")\n",
    "print(f\"最小值位置: {np.argmin(data)}\")\n",
    "\n",
    "# 将一维索引转换为二维索引\n",
    "max_pos = np.unravel_index(np.argmax(data), data.shape)\n",
    "min_pos = np.unravel_index(np.argmin(data), data.shape)\n",
    "print(f\"最大值位置(行,列): {max_pos}\")\n",
    "print(f\"最小值位置(行,列): {min_pos}\")\n",
    "\n",
    "# 按轴统计\n",
    "print(f\"\\n=== 按轴统计 ===\")\n",
    "print(f\"按行求和 (axis=1): {np.sum(data, axis=1)}\")\n",
    "print(f\"按列求和 (axis=0): {np.sum(data, axis=0)}\")\n",
    "print(f\"按行求平均 (axis=1): {np.mean(data, axis=1)}\")\n",
    "print(f\"按列求平均 (axis=0): {np.mean(data, axis=0)}\")\n",
    "\n",
    "# 累积统计\n",
    "print(f\"\\n=== 累积统计 ===\")\n",
    "print(f\"累积和: {np.cumsum(data.flatten())}\")\n",
    "print(f\"累积乘积: {np.cumprod(data.flatten())}\")\n",
    "\n",
    "# 百分位数\n",
    "print(f\"\\n=== 百分位数 ===\")\n",
    "print(f\"25%分位数: {np.percentile(data, 25)}\")\n",
    "print(f\"50%分位数: {np.percentile(data, 50)}\")\n",
    "print(f\"75%分位数: {np.percentile(data, 75)}\")\n",
    "\n",
    "# 条件统计\n",
    "print(f\"\\n=== 条件统计 ===\")\n",
    "print(f\"大于50的元素数量: {np.sum(data > 50)}\")\n",
    "print(f\"大于50的元素比例: {np.mean(data > 50):.2%}\")\n",
    "print(f\"每行中大于50的元素数量: {np.sum(data > 50, axis=1)}\")\n",
    "\n",
    "# 自定义统计函数\n",
    "def custom_range(arr):\n",
    "    \"\"\"自定义函数：计算数组的范围（最大值-最小值）\"\"\"\n",
    "    return np.max(arr) - np.min(arr)\n",
    "\n",
    "print(f\"\\n=== 自定义统计 ===\")\n",
    "print(f\"数据范围: {custom_range(data)}\")\n",
    "print(f\"每行的范围: {[custom_range(row) for row in data]}\")\n",
    "\n",
    "# 练习任务\n",
    "print(\"\\n=== 练习任务 ===\")\n",
    "# 1. 创建一个正态分布的数据\n",
    "normal_data = np.random.normal(50,15,100)\n",
    "print(f\"均值: {np.mean(normal_data)}\")\n",
    "print(f\"标准差: {np.std(normal_data)}\")\n",
    "print(f\"最大值: {np.max(normal_data)}\")\n",
    "print(f\"最小值: {np.min(normal_data)}\")\n",
    "\n",
    "# 2. 分析一个更复杂的数据集\n",
    "complex_data = np.random.rand(2,3)\n",
    "print(f\"复杂数据:\\n{complex_data}\")\n",
    "print(f\"复杂数据形状: {complex_data.shape}\")\n",
    "# 数字越小，就越靠外边\n",
    "print(f\"复杂数据按 axis=0 的平均值: {np.mean(complex_data,axis=0)}\")\n",
    "print(f\"复杂数据按 axis=1 的平均值: {np.mean(complex_data,axis=1)}\")\n",
    "\n",
    "\n",
    "print(\"\\n✅ 统计和聚合函数练习完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. 矩阵运算函数库实现\n",
    "\n",
    "### 学习目标：\n",
    "- 创建一个自定义的矩阵运算类\n",
    "- 实现常用的矩阵运算函数\n",
    "- 理解线性代数在编程中的应用\n",
    "- 为后续的机器学习算法打基础\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建矩阵运算函数库\n",
    "class MatrixOperations:\n",
    "    \"\"\"矩阵运算函数库\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def matrix_multiply(A, B):\n",
    "        \"\"\"矩阵乘法\"\"\"\n",
    "        if A.shape[1] != B.shape[0]:\n",
    "            raise ValueError(f\"矩阵维度不匹配: {A.shape} 和 {B.shape}\")\n",
    "        return np.dot(A, B)\n",
    "    \n",
    "    @staticmethod\n",
    "    def matrix_inverse(A):\n",
    "        \"\"\"矩阵求逆\"\"\"\n",
    "        if A.shape[0] != A.shape[1]:\n",
    "            raise ValueError(\"必须是方阵\")\n",
    "        det = np.linalg.det(A)\n",
    "        if abs(det) < 1e-10:\n",
    "            raise ValueError(\"矩阵不可逆（行列式为0）\")\n",
    "        return np.linalg.inv(A)\n",
    "    \n",
    "    @staticmethod\n",
    "    def matrix_determinant(A):\n",
    "        \"\"\"计算行列式\"\"\"\n",
    "        if A.shape[0] != A.shape[1]:\n",
    "            raise ValueError(\"必须是方阵\")\n",
    "        return np.linalg.det(A)\n",
    "    \n",
    "    @staticmethod\n",
    "    def matrix_trace(A):\n",
    "        \"\"\"计算矩阵的迹\"\"\"\n",
    "        if A.shape[0] != A.shape[1]:\n",
    "            raise ValueError(\"必须是方阵\")\n",
    "        return np.trace(A)\n",
    "    \n",
    "    @staticmethod\n",
    "    def matrix_eigenvalues(A):\n",
    "        \"\"\"计算特征值和特征向量\"\"\"\n",
    "        if A.shape[0] != A.shape[1]:\n",
    "            raise ValueError(\"必须是方阵\")\n",
    "        eigenvalues, eigenvectors = np.linalg.eig(A)\n",
    "        return eigenvalues, eigenvectors\n",
    "    \n",
    "    @staticmethod\n",
    "    def matrix_rank(A):\n",
    "        \"\"\"计算矩阵的秩\"\"\"\n",
    "        return np.linalg.matrix_rank(A)\n",
    "    \n",
    "    @staticmethod\n",
    "    def matrix_norm(A, ord=None):\n",
    "        \"\"\"计算矩阵范数\"\"\"\n",
    "        return np.linalg.norm(A, ord=ord)\n",
    "    \n",
    "    @staticmethod\n",
    "    def matrix_condition_number(A):\n",
    "        \"\"\"计算矩阵条件数\"\"\"\n",
    "        return np.linalg.cond(A)\n",
    "\n",
    "# 测试矩阵运算函数库\n",
    "print(\"=== 矩阵运算函数库测试 ===\")\n",
    "\n",
    "# 创建测试矩阵\n",
    "A = np.array([[1, 2], \n",
    "              [3, 4]])\n",
    "B = np.array([[5, 6], \n",
    "              [7, 8]])\n",
    "C = np.array([[2, 1], \n",
    "              [1, 2]])\n",
    "\n",
    "print(f\"矩阵A:\\n{A}\")\n",
    "print(f\"矩阵B:\\n{B}\")\n",
    "print(f\"矩阵C:\\n{C}\")\n",
    "\n",
    "# 测试矩阵运算\n",
    "mat_ops = MatrixOperations()\n",
    "\n",
    "# 矩阵乘法\n",
    "print(f\"\\n=== 矩阵乘法 ===\")\n",
    "AB = mat_ops.matrix_multiply(A, B)\n",
    "print(f\"A × B:\\n{AB}\")\n",
    "\n",
    "# 行列式\n",
    "print(f\"\\n=== 行列式 ===\")\n",
    "det_A = mat_ops.matrix_determinant(A)\n",
    "det_B = mat_ops.matrix_determinant(B)\n",
    "det_C = mat_ops.matrix_determinant(C)\n",
    "print(f\"det(A) = {det_A}\")\n",
    "print(f\"det(B) = {det_B}\")\n",
    "print(f\"det(C) = {det_C}\")\n",
    "\n",
    "# 矩阵的迹\n",
    "print(f\"\\n=== 矩阵的迹 ===\")\n",
    "trace_A = mat_ops.matrix_trace(A)\n",
    "trace_B = mat_ops.matrix_trace(B)\n",
    "print(f\"trace(A) = {trace_A}\")\n",
    "print(f\"trace(B) = {trace_B}\")\n",
    "\n",
    "# 特征值和特征向量\n",
    "print(f\"\\n=== 特征值和特征向量 ===\")\n",
    "eigenvals_A, eigenvecs_A = mat_ops.matrix_eigenvalues(A)\n",
    "print(f\"A的特征值: {eigenvals_A}\")\n",
    "print(f\"A的特征向量:\\n{eigenvecs_A}\")\n",
    "\n",
    "# 验证特征值和特征向量\n",
    "print(f\"\\n=== 验证特征值和特征向量 ===\")\n",
    "for i in range(len(eigenvals_A)):\n",
    "    lambda_i = eigenvals_A[i]\n",
    "    v_i = eigenvecs_A[:, i]\n",
    "    Av_i = A @ v_i\n",
    "    lambda_v_i = lambda_i * v_i\n",
    "    print(f\"λ{i+1} = {lambda_i:.3f}\")\n",
    "    print(f\"Av{i+1} = {Av_i}\")\n",
    "    print(f\"λ{i+1}v{i+1} = {lambda_v_i}\")\n",
    "    print(f\"误差: {np.allclose(Av_i, lambda_v_i)}\")\n",
    "\n",
    "# 矩阵求逆\n",
    "print(f\"\\n=== 矩阵求逆 ===\")\n",
    "try:\n",
    "    inv_C = mat_ops.matrix_inverse(C)\n",
    "    print(f\"C的逆矩阵:\\n{inv_C}\")\n",
    "    \n",
    "    # 验证逆矩阵\n",
    "    identity = C @ inv_C\n",
    "    print(f\"C × C^(-1) =\\n{identity}\")\n",
    "    print(f\"是否为单位矩阵: {np.allclose(identity, np.eye(2))}\")\n",
    "except ValueError as e:\n",
    "    print(f\"错误: {e}\")\n",
    "\n",
    "# 矩阵秩\n",
    "print(f\"\\n=== 矩阵秩 ===\")\n",
    "rank_A = mat_ops.matrix_rank(A)\n",
    "rank_B = mat_ops.matrix_rank(B)\n",
    "print(f\"rank(A) = {rank_A}\")\n",
    "print(f\"rank(B) = {rank_B}\")\n",
    "\n",
    "# 矩阵范数\n",
    "print(f\"\\n=== 矩阵范数 ===\")\n",
    "norm_A_fro = mat_ops.matrix_norm(A, 'fro')  # Frobenius范数\n",
    "norm_A_2 = mat_ops.matrix_norm(A, 2)        # 2-范数\n",
    "print(f\"A的Frobenius范数: {norm_A_fro:.3f}\")\n",
    "print(f\"A的2-范数: {norm_A_2:.3f}\")\n",
    "\n",
    "# 条件数\n",
    "print(f\"\\n=== 条件数 ===\")\n",
    "cond_A = mat_ops.matrix_condition_number(A)\n",
    "cond_C = mat_ops.matrix_condition_number(C)\n",
    "print(f\"A的条件数: {cond_A:.3f}\")\n",
    "print(f\"C的条件数: {cond_C:.3f}\")\n",
    "\n",
    "# 实际应用示例：解线性方程组\n",
    "print(f\"\\n=== 线性方程组求解 ===\")\n",
    "# 解方程组 Cx = b\n",
    "b = np.array([1, 2])\n",
    "x = np.linalg.solve(C, b)\n",
    "print(f\"方程组 Cx = b\")\n",
    "print(f\"C =\\n{C}\")\n",
    "print(f\"b = {b}\")\n",
    "print(f\"解 x = {x}\")\n",
    "\n",
    "# 验证解\n",
    "verification = C @ x\n",
    "print(f\"验证 Cx = {verification}\")\n",
    "print(f\"是否正确: {np.allclose(verification, b)}\")\n",
    "\n",
    "print(\"\\n✅ 矩阵运算函数库测试完成！\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 6. 挑战任务：实现简单的PCA算法\n",
    "\n",
    "### PCA（主成分分析）是什么？\n",
    "- **降维技术**：将高维数据投影到低维空间\n",
    "- **保留主要信息**：选择能解释最大方差的主成分\n",
    "- **去除冗余**：消除特征之间的相关性\n",
    "\n",
    "### PCA算法步骤：\n",
    "1. **数据中心化**：减去均值\n",
    "2. **计算协方差矩阵**：衡量特征间的相关性\n",
    "3. **特征值分解**：找到主成分方向\n",
    "4. **选择主成分**：保留前k个最大特征值对应的特征向量\n",
    "5. **数据投影**：将原始数据投影到新的坐标系\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现简单的PCA主成分分析\n",
    "def simple_pca(X, n_components=2):\n",
    "    \"\"\"\n",
    "    简单的PCA实现\n",
    "    \n",
    "    参数:\n",
    "    X: 输入数据矩阵 (n_samples, n_features)\n",
    "    n_components: 主成分数量\n",
    "    \n",
    "    返回:\n",
    "    X_pca: 降维后的数据\n",
    "    components: 主成分（特征向量）\n",
    "    eigenvalues: 特征值\n",
    "    explained_variance_ratio: 解释方差比例\n",
    "    \"\"\"\n",
    "    # 步骤1: 数据中心化\n",
    "    X_mean = np.mean(X, axis=0)\n",
    "    X_centered = X - X_mean\n",
    "    \n",
    "    # 步骤2: 计算协方差矩阵\n",
    "    cov_matrix = np.cov(X_centered.T)\n",
    "    \n",
    "    # 步骤3: 计算特征值和特征向量\n",
    "    eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "    \n",
    "    # 步骤4: 按特征值降序排列\n",
    "    idx = np.argsort(eigenvalues)[::-1]\n",
    "    eigenvalues = eigenvalues[idx]\n",
    "    eigenvectors = eigenvectors[:, idx]\n",
    "    \n",
    "    # 步骤5: 选择前n_components个主成分\n",
    "    components = eigenvectors[:, :n_components]\n",
    "    \n",
    "    # 步骤6: 投影数据到新空间\n",
    "    X_pca = np.dot(X_centered, components)\n",
    "    \n",
    "    # 计算解释方差比例\n",
    "    explained_variance_ratio = eigenvalues / np.sum(eigenvalues)\n",
    "    \n",
    "    return X_pca, components, eigenvalues, explained_variance_ratio\n",
    "\n",
    "# 测试PCA算法\n",
    "print(\"=== PCA算法测试 ===\")\n",
    "\n",
    "# 创建具有相关性的测试数据\n",
    "np.random.seed(42)\n",
    "n_samples = 300\n",
    "n_features = 4\n",
    "\n",
    "# 生成原始数据\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "\n",
    "# 在特征之间创建相关性\n",
    "X[:, 1] = X[:, 0] + 0.5 * np.random.randn(n_samples)  # 特征1与特征0相关\n",
    "X[:, 2] = -X[:, 0] + 0.3 * np.random.randn(n_samples)  # 特征2与特征0负相关\n",
    "X[:, 3] = 0.2 * X[:, 0] + 0.8 * np.random.randn(n_samples)  # 特征3与特征0弱相关\n",
    "\n",
    "print(f\"原始数据形状: {X.shape}\")\n",
    "print(f\"原始数据前5行:\\n{X[:5]}\")\n",
    "\n",
    "# 计算原始数据的协方差矩阵\n",
    "orig_cov = np.cov(X.T)\n",
    "print(f\"\\n原始数据协方差矩阵:\\n{orig_cov}\")\n",
    "\n",
    "# 应用PCA\n",
    "X_pca, components, eigenvalues, explained_variance_ratio = simple_pca(X, n_components=2)\n",
    "\n",
    "print(f\"\\nPCA结果:\")\n",
    "print(f\"降维后数据形状: {X_pca.shape}\")\n",
    "print(f\"主成分（特征向量）:\\n{components}\")\n",
    "print(f\"特征值: {eigenvalues}\")\n",
    "print(f\"解释方差比例: {explained_variance_ratio}\")\n",
    "print(f\"前2个主成分累计解释方差比例: {np.sum(explained_variance_ratio[:2]):.3f}\")\n",
    "\n",
    "# 验证PCA的数学特性\n",
    "print(f\"\\n=== PCA验证 ===\")\n",
    "# 1. 主成分应该是正交的\n",
    "dot_product = np.dot(components[:, 0], components[:, 1])\n",
    "print(f\"前两个主成分的点积: {dot_product:.6f} (应该接近0)\")\n",
    "\n",
    "# 2. 主成分应该是单位向量\n",
    "norm1 = np.linalg.norm(components[:, 0])\n",
    "norm2 = np.linalg.norm(components[:, 1])\n",
    "print(f\"第一主成分的模长: {norm1:.6f} (应该等于1)\")\n",
    "print(f\"第二主成分的模长: {norm2:.6f} (应该等于1)\")\n",
    "\n",
    "# 3. 降维后数据的均值应该为0\n",
    "mean_pca = np.mean(X_pca, axis=0)\n",
    "print(f\"降维后数据的均值: {mean_pca} (应该接近0)\")\n",
    "\n",
    "# 数据重构\n",
    "print(f\"\\n=== 数据重构 ===\")\n",
    "# 使用前2个主成分重构原始数据\n",
    "X_reconstructed = np.dot(X_pca, components.T) + np.mean(X, axis=0)\n",
    "reconstruction_error = np.mean((X - X_reconstructed)**2)\n",
    "print(f\"重构误差 (MSE): {reconstruction_error:.6f}\")\n",
    "\n",
    "# 比较原始数据和重构数据\n",
    "print(f\"原始数据前3行:\\n{X[:3]}\")\n",
    "print(f\"重构数据前3行:\\n{X_reconstructed[:3]}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 7. 数据可视化进阶\n",
    "\n",
    "### 今天的可视化目标：\n",
    "- 创建多子图布局\n",
    "- 可视化PCA降维结果\n",
    "- 展示不同类型的图表\n",
    "- 解决中文字体显示问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 数据可视化进阶\n",
    "print(\"=== 数据可视化进阶 ===\")\n",
    "\n",
    "# 创建多子图布局\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "fig.suptitle('NumPy进阶操作可视化示例', fontsize=16, fontweight='bold')\n",
    "\n",
    "# 子图1：PCA降维结果\n",
    "ax1 = axes[0, 0]\n",
    "# 使用颜色区分不同区域的数据点\n",
    "colors = ['red' if x > 0 else 'blue' for x in X_pca[:, 0]]\n",
    "ax1.scatter(X_pca[:, 0], X_pca[:, 1], c=colors, alpha=0.6, s=30)\n",
    "ax1.set_title('PCA降维结果')\n",
    "ax1.set_xlabel('第一主成分')\n",
    "ax1.set_ylabel('第二主成分')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 子图2：特征值解释方差比例\n",
    "ax2 = axes[0, 1]\n",
    "components_num = np.arange(1, len(explained_variance_ratio) + 1)\n",
    "ax2.bar(components_num, explained_variance_ratio, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "ax2.set_title('主成分解释方差比例')\n",
    "ax2.set_xlabel('主成分')\n",
    "ax2.set_ylabel('解释方差比例')\n",
    "ax2.set_xticks(components_num)\n",
    "for i, v in enumerate(explained_variance_ratio):\n",
    "    ax2.text(i+1, v + 0.01, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 子图3：累计解释方差比例\n",
    "ax3 = axes[0, 2]\n",
    "cumulative_variance = np.cumsum(explained_variance_ratio)\n",
    "ax3.plot(components_num, cumulative_variance, 'o-', linewidth=2, markersize=8, color='green')\n",
    "ax3.set_title('累计解释方差比例')\n",
    "ax3.set_xlabel('主成分数量')\n",
    "ax3.set_ylabel('累计解释方差比例')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_ylim(0, 1.1)\n",
    "for i, v in enumerate(cumulative_variance):\n",
    "    ax3.text(i+1, v + 0.02, f'{v:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# 子图4：原始数据分布（选择前两个特征）\n",
    "ax4 = axes[1, 0]\n",
    "ax4.scatter(X[:, 0], X[:, 1], alpha=0.6, c='purple', s=30)\n",
    "ax4.set_title('原始数据分布（特征0 vs 特征1）')\n",
    "ax4.set_xlabel('特征0')\n",
    "ax4.set_ylabel('特征1')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# 子图5：协方差矩阵热力图\n",
    "ax5 = axes[1, 1]\n",
    "im = ax5.imshow(orig_cov, cmap='coolwarm', aspect='auto')\n",
    "ax5.set_title('原始数据协方差矩阵')\n",
    "ax5.set_xlabel('特征')\n",
    "ax5.set_ylabel('特征')\n",
    "# 添加颜色条\n",
    "plt.colorbar(im, ax=ax5, fraction=0.046, pad=0.04)\n",
    "# 添加数值标注\n",
    "for i in range(orig_cov.shape[0]):\n",
    "    for j in range(orig_cov.shape[1]):\n",
    "        text = ax5.text(j, i, f'{orig_cov[i, j]:.2f}', \n",
    "                       ha=\"center\", va=\"center\", color=\"black\", fontsize=10)\n",
    "\n",
    "# 子图6：重构误差分析\n",
    "ax6 = axes[1, 2]\n",
    "# 计算不同主成分数量的重构误差\n",
    "reconstruction_errors = []\n",
    "for n_comp in range(1, n_features + 1):\n",
    "    X_pca_temp, components_temp, _, _ = simple_pca(X, n_components=n_comp)\n",
    "    X_reconstructed_temp = np.dot(X_pca_temp, components_temp.T) + np.mean(X, axis=0)\n",
    "    error = np.mean((X - X_reconstructed_temp)**2)\n",
    "    reconstruction_errors.append(error)\n",
    "\n",
    "ax6.plot(range(1, n_features + 1), reconstruction_errors, 'o-', linewidth=2, markersize=8, color='red')\n",
    "ax6.set_title('重构误差 vs 主成分数量')\n",
    "ax6.set_xlabel('主成分数量')\n",
    "ax6.set_ylabel('重构误差 (MSE)')\n",
    "ax6.grid(True, alpha=0.3)\n",
    "ax6.set_xticks(range(1, n_features + 1))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 创建额外的可视化：3D散点图（如果有3个或更多特征）\n",
    "if X.shape[1] >= 3:\n",
    "    fig = plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # 3D原始数据\n",
    "    ax1 = fig.add_subplot(121, projection='3d')\n",
    "    ax1.scatter(X[:, 0], X[:, 1], X[:, 2], alpha=0.6, c='blue', s=30)\n",
    "    ax1.set_title('原始数据 (3D)')\n",
    "    ax1.set_xlabel('特征0')\n",
    "    ax1.set_ylabel('特征1')\n",
    "    ax1.set_zlabel('特征2')\n",
    "    \n",
    "    # 2D PCA结果\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.scatter(X_pca[:, 0], X_pca[:, 1], alpha=0.6, c='red', s=30)\n",
    "    ax2.set_title('PCA降维结果 (2D)')\n",
    "    ax2.set_xlabel('第一主成分')\n",
    "    ax2.set_ylabel('第二主成分')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 创建主成分向量可视化\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "feature_names = [f'特征{i}' for i in range(X.shape[1])]\n",
    "x_pos = np.arange(len(feature_names))\n",
    "\n",
    "# 绘制前两个主成分\n",
    "width = 0.35\n",
    "ax.bar(x_pos - width/2, components[:, 0], width, label='第一主成分', alpha=0.7)\n",
    "ax.bar(x_pos + width/2, components[:, 1], width, label='第二主成分', alpha=0.7)\n",
    "\n",
    "ax.set_xlabel('特征')\n",
    "ax.set_ylabel('主成分系数')\n",
    "ax.set_title('主成分系数')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(feature_names)\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ 数据可视化完成！\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 8. 今日总结与反思\n",
    "\n",
    "### 🎯 今日完成的内容\n",
    "1. ✅ **高级索引和切片**：掌握了布尔索引、花式索引等高级技巧\n",
    "2. ✅ **广播机制**：理解了NumPy自动扩展数组维度的强大功能  \n",
    "3. ✅ **数组形状操作**：学会了reshape、transpose、concatenate等操作\n",
    "4. ✅ **统计和聚合函数**：掌握了数据分析的基本工具\n",
    "5. ✅ **矩阵运算函数库**：实现了完整的线性代数运算工具\n",
    "6. ✅ **PCA算法**：从零实现了主成分分析算法\n",
    "7. ✅ **数据可视化**：创建了多种专业的数据图表\n",
    "\n",
    "### 💡 重要发现和收获\n",
    "- **广播机制的威力**：让不同形状的数组能够直接运算\n",
    "- **线性代数的实用性**：PCA算法展示了数学理论在实际中的应用\n",
    "- **代码的模块化**：通过类和函数组织代码，提高了复用性\n",
    "- **可视化的重要性**：图表能够直观地展示复杂的数据关系\n",
    "\n",
    "### 🔍 需要进一步学习的内容\n",
    "- 更深入的线性代数理论\n",
    "- 其他降维算法（如SVD、t-SNE）\n",
    "- 更高级的可视化技术\n",
    "- 大规模数据的处理优化\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二天学习完成庆祝！\n",
    "print(\"🎉\" * 50)\n",
    "print(\"恭喜你完成了第二天的学习！\")\n",
    "print(\"🎉\" * 50)\n",
    "\n",
    "print(\"\\n📊 今日学习统计:\")\n",
    "print(\"- 掌握了NumPy高级操作\")\n",
    "print(\"- 实现了PCA算法\") \n",
    "print(\"- 创建了矩阵运算函数库\")\n",
    "print(\"- 制作了多种可视化图表\")\n",
    "print(\"- 解决了中文字体显示问题\")\n",
    "\n",
    "print(\"\\n🚀 明日预告 - 第三天：线性代数基础\")\n",
    "print(\"- 观看3Blue1Brown《线性代数的本质》第1-2集\")\n",
    "print(\"- 理解向量的几何意义\")\n",
    "print(\"- 学习向量加法和标量乘法\")\n",
    "print(\"- 用NumPy实现向量运算\")\n",
    "print(\"- 开始接触线性代数的编程实现\")\n",
    "\n",
    "print(\"\\n💪 继续保持这样的学习节奏！\")\n",
    "print(\"每一天的积累都在让你更接近大模型研发工程师的目标！\")\n",
    "\n",
    "print(f\"\\n📈 学习进度更新:\")\n",
    "print(\"第1天: ✅ Python环境搭建 + NumPy基础\") \n",
    "print(\"第2天: ✅ NumPy进阶操作\")\n",
    "print(\"第3天: ⏳ 线性代数基础\")\n",
    "print(\"...\")\n",
    "print(\"目标: 🎯 大模型研发工程师\")\n",
    "\n",
    "print(\"\\n\" + \"🌟\" * 50)\n",
    "print(\"坚持就是胜利！明天见！\")\n",
    "print(\"🌟\" * 50)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "# 第二天：NumPy进阶操作\n",
    "\n",
    "## 今日学习目标\n",
    "1. 掌握NumPy数组的高级索引和切片\n",
    "2. 理解广播机制（Broadcasting）\n",
    "3. 学习数组的形状操作\n",
    "4. 实现矩阵运算函数\n",
    "5. 解决中文字体显示问题\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "# 解决中文字体显示问题\n",
    "plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"NumPy版本:\", np.__version__)\n",
    "print(\"第二天学习开始！\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 1. 数组索引和切片进阶\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 2. 广播机制（Broadcasting）练习\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 广播机制练习\n",
    "print(\"=== 广播机制练习 ===\")\n",
    "\n",
    "# 创建测试数组\n",
    "matrix_a = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "vector_b = np.array([10, 20, 30])\n",
    "\n",
    "print(f\"矩阵A形状: {matrix_a.shape}\")\n",
    "print(f\"矩阵A:\\n{matrix_a}\")\n",
    "print(f\"向量B形状: {vector_b.shape}\")\n",
    "print(f\"向量B: {vector_b}\")\n",
    "\n",
    "# 练习任务：\n",
    "# 1. 计算矩阵A与向量B的相加结果\n",
    "# 2. 计算矩阵A与向量B的相乘结果\n",
    "# 3. 尝试创建一个(3,1)的向量C，与矩阵A进行广播运算\n",
    "# 4. 理解广播的规则\n",
    "\n",
    "# 请在下面完成练习：\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 3. 矩阵运算函数库实现\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建矩阵运算函数库\n",
    "class MatrixOperations:\n",
    "    \"\"\"矩阵运算函数库\"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def matrix_multiply(A, B):\n",
    "        \"\"\"矩阵乘法 - 请实现这个函数\"\"\"\n",
    "        # 提示：检查维度是否匹配，然后使用np.dot()\n",
    "        pass\n",
    "    \n",
    "    @staticmethod  \n",
    "    def matrix_determinant(A):\n",
    "        \"\"\"计算行列式 - 请实现这个函数\"\"\"\n",
    "        # 提示：检查是否为方阵，然后使用np.linalg.det()\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def matrix_trace(A):\n",
    "        \"\"\"计算矩阵的迹 - 请实现这个函数\"\"\"\n",
    "        # 提示：矩阵的迹是主对角线元素之和，使用np.trace()\n",
    "        pass\n",
    "    \n",
    "    @staticmethod\n",
    "    def matrix_eigenvalues(A):\n",
    "        \"\"\"计算特征值和特征向量 - 请实现这个函数\"\"\"\n",
    "        # 提示：使用np.linalg.eig()\n",
    "        pass\n",
    "\n",
    "# 测试你的函数库\n",
    "print(\"=== 矩阵运算函数库测试 ===\")\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "print(f\"矩阵A:\\n{A}\")\n",
    "print(f\"矩阵B:\\n{B}\")\n",
    "\n",
    "# 请在这里测试你实现的函数：\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 4. 挑战任务：实现简单的PCA算法\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现简单的PCA主成分分析\n",
    "def simple_pca(X, n_components=2):\n",
    "    \"\"\"\n",
    "    简单的PCA实现 - 请完成这个函数\n",
    "    \n",
    "    参数:\n",
    "    X: 输入数据矩阵 (n_samples, n_features)\n",
    "    n_components: 主成分数量\n",
    "    \n",
    "    返回:\n",
    "    X_pca: 降维后的数据\n",
    "    components: 主成分\n",
    "    eigenvalues: 特征值\n",
    "    \"\"\"\n",
    "    # 步骤1: 中心化数据（减去均值）\n",
    "    # 提示：使用 X - np.mean(X, axis=0)\n",
    "    \n",
    "    # 步骤2: 计算协方差矩阵\n",
    "    # 提示：使用 np.cov(X_centered.T)\n",
    "    \n",
    "    # 步骤3: 计算特征值和特征向量\n",
    "    # 提示：使用 np.linalg.eig()\n",
    "    \n",
    "    # 步骤4: 按特征值降序排列\n",
    "    # 提示：使用 np.argsort()[::-1]\n",
    "    \n",
    "    # 步骤5: 选择前n_components个主成分\n",
    "    \n",
    "    # 步骤6: 投影数据到新空间\n",
    "    # 提示：使用 np.dot(X_centered, components)\n",
    "    \n",
    "    # 请在这里实现PCA算法：\n",
    "    pass\n",
    "\n",
    "# 测试PCA算法\n",
    "print(\"=== PCA算法测试 ===\")\n",
    "# 创建测试数据\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(100, 4)  # 100个样本，4个特征\n",
    "X[:, 1] = X[:, 0] + 0.5 * np.random.randn(100)  # 创建相关性\n",
    "\n",
    "print(f\"原始数据形状: {X.shape}\")\n",
    "print(f\"原始数据前5行:\\n{X[:5]}\")\n",
    "\n",
    "# 请在这里测试你的PCA实现：\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "## 5. 今日总结\n",
    "\n",
    "### 完成情况自检：\n",
    "- [ ] 掌握了NumPy高级索引和切片\n",
    "- [ ] 理解了广播机制的原理\n",
    "- [ ] 学会了数组形状操作\n",
    "- [ ] 创建了矩阵运算函数库\n",
    "- [ ] 实现了简单的PCA算法\n",
    "\n",
    "### 明日预告：\n",
    "- 线性代数基础概念\n",
    "- 向量和矩阵的几何意义\n",
    "- 观看3Blue1Brown的线性代数系列\n",
    "\n",
    "**恭喜你完成了第二天的学习！🎉**\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (quant)",
   "language": "python",
   "name": "quant"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
