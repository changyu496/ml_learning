{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 第10天：分类算法进阶实战 🚀\n",
        "\n",
        "## 🎯 今日目标\n",
        "1. **回顾第9天练习题** - 检查理解程度\n",
        "2. **掌握交叉验证** - 评估模型稳定性\n",
        "3. **学习模型调优** - GridSearchCV参数优化\n",
        "4. **实战新数据集** - 乳腺癌诊断项目\n",
        "5. **模型对比分析** - 深入理解算法差异\n",
        "\n",
        "## 📚 今日重点\n",
        "- 练习题解答与深入理解\n",
        "- 交叉验证与模型评估\n",
        "- 超参数调优技术\n",
        "- 实际医疗诊断项目\n",
        "- 特征工程与可视化"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 1. 第9天练习题回顾与解答 📝\n",
        "\n",
        "## 1.1 基础理解题解答\n",
        "\n",
        "**Q1: 分类与回归的主要区别？**\n",
        "\n",
        "**答案：**\n",
        "- **分类**：输出离散类别标签（如：垃圾邮件/正常邮件）\n",
        "- **回归**：输出连续数值（如：房价预测）\n",
        "- **评估指标**：分类用准确率、精确率、召回率；回归用MSE、R²\n",
        "\n",
        "**Q2: 逻辑回归为什么用sigmoid函数？**\n",
        "\n",
        "**答案：**\n",
        "- 将线性输出压缩到(0,1)区间，表示概率\n",
        "- 便于优化，有良好的数学性质（可导、单调）\n",
        "- 输出可以解释为样本属于正类的概率\n",
        "\n",
        "**Q3: 决策树如何选择分裂特征？**\n",
        "\n",
        "**答案：**\n",
        "- **信息增益**：选择能最大程度减少不确定性的特征\n",
        "- **基尼指数**：选择能最大程度减少不纯度的特征\n",
        "- **目标**：让子节点尽可能纯净（同一类别）\n",
        "\n",
        "**Q4: 混淆矩阵如何解读？**\n",
        "\n",
        "**答案：**\n",
        "- **对角线**：正确分类的样本数\n",
        "- **非对角线**：错误分类的样本数\n",
        "- **精确率** = TP / (TP + FP)\n",
        "- **召回率** = TP / (TP + FN)\n",
        "\n",
        "**Q5: 逻辑回归vs决策树优缺点？**\n",
        "\n",
        "**答案：**\n",
        "- **逻辑回归**：训练快、不易过拟合、可解释性强，但只能处理线性关系\n",
        "- **决策树**：可处理非线性关系、特征重要性明确，但容易过拟合"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 导入必要的库\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, confusion_matrix, classification_report,\n",
        "    precision_score, recall_score, f1_score, roc_curve, auc\n",
        ")\n",
        "from sklearn.datasets import load_iris, load_breast_cancer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 设置中文字体\n",
        "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
        "plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "print(\"✅ 库导入成功！\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. 交叉验证与模型稳定性评估 📊\n",
        "\n",
        "## 2.1 为什么需要交叉验证？\n",
        "\n",
        "**问题**：只用一次train_test_split评估模型可靠吗？\n",
        "\n",
        "**答案**：不可靠！因为：\n",
        "- 数据划分的随机性会影响结果\n",
        "- 可能过拟合到特定的训练/测试集\n",
        "- 无法评估模型的泛化能力\n",
        "\n",
        "**解决方案**：交叉验证（Cross-Validation）\n",
        "- 多次划分数据，取平均性能\n",
        "- 更准确地评估模型稳定性\n",
        "- 减少随机性影响"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载鸢尾花数据集\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "print(f\"数据集形状: X={X.shape}, y={y.shape}\")\n",
        "print(f\"特征名称: {iris.feature_names}\")\n",
        "print(f\"类别名称: {iris.target_names}\")\n",
        "\n",
        "# 对比：单次划分 vs 交叉验证\n",
        "print(\"\\n🔍 单次划分结果:\")\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
        "logreg.fit(X_train, y_train)\n",
        "single_score = logreg.score(X_test, y_test)\n",
        "print(f\"单次划分准确率: {single_score:.4f}\")\n",
        "\n",
        "# 交叉验证\n",
        "print(\"\\n📊 交叉验证结果:\")\n",
        "cv_scores = cross_val_score(logreg, X, y, cv=5)\n",
        "print(f\"5折交叉验证分数: {cv_scores}\")\n",
        "print(f\"平均准确率: {cv_scores.mean():.4f}\")\n",
        "print(f\"标准差: {cv_scores.std():.4f}\")\n",
        "print(f\"95%置信区间: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
        "\n",
        "# 可视化交叉验证结果\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.bar(['单次划分', '交叉验证'], [single_score, cv_scores.mean()])\n",
        "plt.ylabel('准确率')\n",
        "plt.title('单次划分 vs 交叉验证')\n",
        "plt.ylim(0.8, 1.0)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(range(1, 6), cv_scores, 'o-', linewidth=2, markersize=8)\n",
        "plt.xlabel('折数')\n",
        "plt.ylabel('准确率')\n",
        "plt.title('5折交叉验证分数变化')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. 超参数调优实战 🔧\n",
        "\n",
        "## 3.1 GridSearchCV参数优化\n",
        "\n",
        "**问题**：如何找到最优的超参数？\n",
        "\n",
        "**解决方案**：网格搜索（Grid Search）\n",
        "- 遍历所有参数组合\n",
        "- 使用交叉验证评估\n",
        "- 选择最佳参数组合"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 逻辑回归参数调优\n",
        "print(\"🔧 逻辑回归参数调优:\")\n",
        "param_grid_logreg = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],  # 正则化强度\n",
        "    'penalty': ['l1', 'l2'],         # 正则化类型\n",
        "    'solver': ['liblinear']          # 优化算法\n",
        "}\n",
        "\n",
        "grid_logreg = GridSearchCV(\n",
        "    LogisticRegression(max_iter=1000, random_state=42),\n",
        "    param_grid_logreg, cv=5, scoring='accuracy', n_jobs=-1\n",
        ")\n",
        "grid_logreg.fit(X, y)\n",
        "\n",
        "print(f\"最优参数: {grid_logreg.best_params_}\")\n",
        "print(f\"最优交叉验证分数: {grid_logreg.best_score_:.4f}\")\n",
        "print(f\"参数搜索空间大小: {len(grid_logreg.cv_results_['params'])}\")\n",
        "\n",
        "# 决策树参数调优\n",
        "print(\"\\n🌳 决策树参数调优:\")\n",
        "param_grid_tree = {\n",
        "    'max_depth': [2, 3, 4, 5, 6, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "grid_tree = GridSearchCV(\n",
        "    DecisionTreeClassifier(random_state=42),\n",
        "    param_grid_tree, cv=5, scoring='accuracy', n_jobs=-1\n",
        ")\n",
        "grid_tree.fit(X, y)\n",
        "\n",
        "print(f\"最优参数: {grid_tree.best_params_}\")\n",
        "print(f\"最优交叉验证分数: {grid_tree.best_score_:.4f}\")\n",
        "\n",
        "# 可视化调优结果\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# 逻辑回归调优结果\n",
        "plt.subplot(1, 2, 1)\n",
        "results_logreg = pd.DataFrame(grid_logreg.cv_results_)\n",
        "best_logreg = results_logreg[results_logreg['rank_test_score'] == 1].iloc[0]\n",
        "print(f\"\\n逻辑回归调优提升: {best_logreg['mean_test_score'] - cv_scores.mean():.4f}\")\n",
        "\n",
        "# 决策树调优结果\n",
        "plt.subplot(1, 2, 2)\n",
        "results_tree = pd.DataFrame(grid_tree.cv_results_)\n",
        "best_tree = results_tree[results_tree['rank_test_score'] == 1].iloc[0]\n",
        "print(f\"决策树调优提升: {best_tree['mean_test_score'] - cv_scores.mean():.4f}\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. 实战项目：乳腺癌诊断 🏥\n",
        "\n",
        "## 4.1 数据集介绍\n",
        "\n",
        "**乳腺癌数据集特点：**\n",
        "- 569个样本，30个特征\n",
        "- 二分类问题：恶性(0) vs 良性(1)\n",
        "- 特征为细胞核的测量值\n",
        "- 医疗诊断的经典数据集\n",
        "\n",
        "**为什么选择这个数据集？**\n",
        "- 特征数量多，需要特征工程\n",
        "- 医疗诊断，对模型性能要求高\n",
        "- 数据不平衡，需要特殊处理"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 加载乳腺癌数据集\n",
        "cancer = load_breast_cancer()\n",
        "X_cancer = cancer.data\n",
        "y_cancer = cancer.target\n",
        "\n",
        "print(f\"乳腺癌数据集形状: X={X_cancer.shape}, y={y_cancer.shape}\")\n",
        "print(f\"类别分布: {np.bincount(y_cancer)}\")\n",
        "print(f\"类别含义: 0=恶性, 1=良性\")\n",
        "print(f\"特征数量: {X_cancer.shape[1]}\")\n",
        "\n",
        "# 数据预处理 - 特征缩放\n",
        "print(\"\\n🔧 数据预处理:\")\n",
        "scaler = StandardScaler()\n",
        "X_cancer_scaled = scaler.fit_transform(X_cancer)\n",
        "\n",
        "print(f\"原始数据范围: [{X_cancer.min():.2f}, {X_cancer.max():.2f}]\")\n",
        "print(f\"缩放后范围: [{X_cancer_scaled.min():.2f}, {X_cancer_scaled.max():.2f}]\")\n",
        "\n",
        "# 划分数据集\n",
        "X_train_cancer, X_test_cancer, y_train_cancer, y_test_cancer = train_test_split(\n",
        "    X_cancer_scaled, y_cancer, test_size=0.2, random_state=42, stratify=y_cancer\n",
        ")\n",
        "\n",
        "print(f\"\\n训练集大小: {X_train_cancer.shape[0]}\")\n",
        "print(f\"测试集大小: {X_test_cancer.shape[0]}\")\n",
        "\n",
        "# 训练模型\n",
        "print(\"\\n🏥 模型训练与评估:\")\n",
        "logreg_cancer = LogisticRegression(random_state=42)\n",
        "dtree_cancer = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "\n",
        "logreg_cancer.fit(X_train_cancer, y_train_cancer)\n",
        "dtree_cancer.fit(X_train_cancer, y_train_cancer)\n",
        "\n",
        "# 预测\n",
        "y_pred_logreg_cancer = logreg_cancer.predict(X_test_cancer)\n",
        "y_pred_dtree_cancer = dtree_cancer.predict(X_test_cancer)\n",
        "\n",
        "# 评估\n",
        "print(f\"逻辑回归准确率: {accuracy_score(y_test_cancer, y_pred_logreg_cancer):.4f}\")\n",
        "print(f\"决策树准确率: {accuracy_score(y_test_cancer, y_pred_dtree_cancer):.4f}\")\n",
        "\n",
        "print(\"\\n逻辑回归详细评估:\")\n",
        "print(classification_report(y_test_cancer, y_pred_logreg_cancer, \n",
        "                          target_names=['恶性', '良性']))\n",
        "\n",
        "print(\"\\n决策树详细评估:\")\n",
        "print(classification_report(y_test_cancer, y_pred_dtree_cancer, \n",
        "                          target_names=['恶性', '良性']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 5. 特征工程与可视化 📊\n",
        "\n",
        "## 5.1 特征重要性分析\n",
        "\n",
        "在医疗诊断中，了解哪些特征最重要非常关键！"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 特征重要性分析\n",
        "print(\"🔍 特征重要性分析:\")\n",
        "\n",
        "# 逻辑回归特征重要性（系数绝对值）\n",
        "logreg_importance = np.abs(logreg_cancer.coef_[0])\n",
        "feature_names = cancer.feature_names\n",
        "\n",
        "# 获取前10个最重要的特征\n",
        "top_indices = np.argsort(logreg_importance)[-10:]\n",
        "top_features = [feature_names[i] for i in top_indices]\n",
        "top_importance = logreg_importance[top_indices]\n",
        "\n",
        "print(\"\\n逻辑回归 - 前10个最重要特征:\")\n",
        "for name, importance in zip(top_features, top_importance):\n",
        "    print(f\"  {name}: {importance:.4f}\")\n",
        "\n",
        "# 决策树特征重要性\n",
        "tree_importance = dtree_cancer.feature_importances_\n",
        "top_tree_indices = np.argsort(tree_importance)[-10:]\n",
        "top_tree_features = [feature_names[i] for i in top_tree_indices]\n",
        "top_tree_importance = tree_importance[top_tree_indices]\n",
        "\n",
        "print(\"\\n决策树 - 前10个最重要特征:\")\n",
        "for name, importance in zip(top_tree_features, top_tree_importance):\n",
        "    print(f\"  {name}: {importance:.4f}\")\n",
        "\n",
        "# 可视化特征重要性\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.barh(range(len(top_features)), top_importance)\n",
        "plt.yticks(range(len(top_features)), top_features)\n",
        "plt.xlabel('重要性')\n",
        "plt.title('逻辑回归特征重要性（前10）')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.barh(range(len(top_tree_features)), top_tree_importance)\n",
        "plt.yticks(range(len(top_tree_features)), top_tree_features)\n",
        "plt.xlabel('重要性')\n",
        "plt.title('决策树特征重要性（前10）')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 特征相关性分析\n",
        "print(\"\\n📊 特征相关性分析:\")\n",
        "df_cancer = pd.DataFrame(X_cancer_scaled, columns=cancer.feature_names)\n",
        "df_cancer['target'] = y_cancer\n",
        "\n",
        "# 计算与目标的相关性\n",
        "correlations = df_cancer.corr()['target'].abs().sort_values(ascending=False)\n",
        "print(\"\\n与目标变量相关性最高的特征:\")\n",
        "print(correlations.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 6. 模型对比与总结 📈\n",
        "\n",
        "## 6.1 综合性能对比\n",
        "\n",
        "让我们对比两个模型在不同指标上的表现："
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 综合性能对比\n",
        "print(\"📊 模型性能综合对比:\")\n",
        "\n",
        "# 计算各种指标\n",
        "def calculate_metrics(y_true, y_pred, model_name):\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    \n",
        "    print(f\"\\n{model_name}:\")\n",
        "    print(f\"  准确率: {accuracy:.4f}\")\n",
        "    print(f\"  精确率: {precision:.4f}\")\n",
        "    print(f\"  召回率: {recall:.4f}\")\n",
        "    print(f\"  F1分数: {f1:.4f}\")\n",
        "    \n",
        "    return [accuracy, precision, recall, f1]\n",
        "\n",
        "# 计算指标\n",
        "logreg_metrics = calculate_metrics(y_test_cancer, y_pred_logreg_cancer, \"逻辑回归\")\n",
        "tree_metrics = calculate_metrics(y_test_cancer, y_pred_dtree_cancer, \"决策树\")\n",
        "\n",
        "# 可视化对比\n",
        "metrics_names = ['准确率', '精确率', '召回率', 'F1分数']\n",
        "x = np.arange(len(metrics_names))\n",
        "width = 0.35\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(x - width/2, logreg_metrics, width, label='逻辑回归', color='skyblue')\n",
        "plt.bar(x + width/2, tree_metrics, width, label='决策树', color='lightcoral')\n",
        "\n",
        "plt.xlabel('评估指标')\n",
        "plt.ylabel('分数')\n",
        "plt.title('模型性能对比')\n",
        "plt.xticks(x, metrics_names)\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 交叉验证对比\n",
        "print(\"\\n📈 交叉验证稳定性对比:\")\n",
        "cv_logreg = cross_val_score(logreg_cancer, X_cancer_scaled, y_cancer, cv=5)\n",
        "cv_tree = cross_val_score(dtree_cancer, X_cancer_scaled, y_cancer, cv=5)\n",
        "\n",
        "print(f\"逻辑回归CV: {cv_logreg.mean():.4f} (+/- {cv_logreg.std() * 2:.4f})\")\n",
        "print(f\"决策树CV: {cv_tree.mean():.4f} (+/- {cv_tree.std() * 2:.4f})\")\n",
        "\n",
        "# 可视化交叉验证结果\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.boxplot([cv_logreg, cv_tree], labels=['逻辑回归', '决策树'])\n",
        "plt.ylabel('交叉验证准确率')\n",
        "plt.title('模型稳定性对比')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 7. 进阶练习与思考题 💭\n",
        "\n",
        "## 7.1 编程练习题\n",
        "\n",
        "1. **特征选择实验**：只用前5个最重要的特征训练模型，观察性能变化\n",
        "2. **参数调优**：对乳腺癌数据集进行更深入的GridSearchCV调优\n",
        "3. **ROC曲线**：为乳腺癌数据集绘制ROC曲线，比较两个模型\n",
        "4. **数据不平衡**：如果恶性样本只有10%，如何处理？\n",
        "\n",
        "## 7.2 思考题\n",
        "\n",
        "1. **为什么乳腺癌数据集需要特征缩放？**\n",
        "2. **在医疗诊断中，精确率和召回率哪个更重要？为什么？**\n",
        "3. **如何解释决策树在乳腺癌数据集上的特征重要性？**\n",
        "4. **如果数据不平衡，应该如何处理？**\n",
        "5. **交叉验证为什么比单次划分更可靠？**\n",
        "\n",
        "## 7.3 实战挑战\n",
        "\n",
        "尝试用其他数据集（如手写数字数据集）进行多分类实验，并总结不同算法的适用场景。\n",
        "\n",
        "---\n",
        "**今日总结**：你已经掌握了分类算法的进阶应用！明天我们将学习更高级的算法。"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
