"""
MSEå¯è§†åŒ–æ¼”ç¤º - ç†è§£æœ€å°åŒ–å‡æ–¹è¯¯å·®
"""

import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False

# ç”Ÿæˆç¤ºä¾‹æ•°æ®
np.random.seed(42)
X = np.random.rand(20, 1) * 10
y = 2 * X + 1 + np.random.normal(0, 0.5, (20, 1))

print("ğŸ¯ MSEå¯è§†åŒ–æ¼”ç¤º")
print("="*50)

# è®¡ç®—ä¸åŒå‚æ•°ä¸‹çš„MSE
def calculate_mse(X, y, beta_0, beta_1):
    """è®¡ç®—ç»™å®šå‚æ•°ä¸‹çš„MSE"""
    y_pred = beta_0 + beta_1 * X
    mse = np.mean((y - y_pred) ** 2)
    return mse

# æµ‹è¯•ä¸åŒçš„å‚æ•°ç»„åˆ
beta_0_range = np.linspace(-2, 4, 50)
beta_1_range = np.linspace(0, 4, 50)
mse_values = []

print("è®¡ç®—ä¸åŒå‚æ•°ç»„åˆçš„MSE...")
for beta_0 in beta_0_range:
    for beta_1 in beta_1_range:
        mse = calculate_mse(X, y, beta_0, beta_1)
        mse_values.append((beta_0, beta_1, mse))

# æ‰¾åˆ°æœ€ä½³å‚æ•°
best_params = min(mse_values, key=lambda x: x[2])
print(f"æœ€ä½³å‚æ•°: Î²â‚€ = {best_params[0]:.3f}, Î²â‚ = {best_params[1]:.3f}")
print(f"æœ€å°MSE: {best_params[2]:.4f}")

# å¯è§†åŒ–1ï¼šMSEç­‰é«˜çº¿å›¾
print("\nğŸ“Š å¯è§†åŒ–1: MSEç­‰é«˜çº¿å›¾")
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

# å‡†å¤‡ç½‘æ ¼æ•°æ®
beta_0_grid, beta_1_grid = np.meshgrid(beta_0_range, beta_1_range)
mse_grid = np.zeros_like(beta_0_grid)

for i in range(len(beta_0_range)):
    for j in range(len(beta_1_range)):
        mse_grid[j, i] = calculate_mse(X, y, beta_0_range[i], beta_1_range[j])

# ç­‰é«˜çº¿å›¾
contour = ax1.contour(beta_0_grid, beta_1_grid, mse_grid, levels=20)
ax1.clabel(contour, inline=True, fontsize=8)
ax1.scatter(best_params[0], best_params[1], color='red', s=100, marker='*', label='æœ€ä½³å‚æ•°')
ax1.set_xlabel('Î²â‚€ (æˆªè·)')
ax1.set_ylabel('Î²â‚ (æ–œç‡)')
ax1.set_title('MSEç­‰é«˜çº¿å›¾\n(é¢œè‰²è¶Šæ·±ï¼ŒMSEè¶Šå°)')
ax1.legend()
ax1.grid(True, alpha=0.3)

# å¯è§†åŒ–2ï¼šæ•°æ®æ‹Ÿåˆå¯¹æ¯”
print("ğŸ“Š å¯è§†åŒ–2: ä¸åŒå‚æ•°ä¸‹çš„æ‹Ÿåˆæ•ˆæœ")

# æœ€ä½³æ‹Ÿåˆçº¿
y_best = best_params[0] + best_params[1] * X

# éšæœºé€‰æ‹©å‡ ä¸ªä¸å¥½çš„å‚æ•°
bad_params = [
    (0, 0.5, "å‚æ•°å¤ªå·®"),
    (3, 0.5, "æˆªè·å¤ªå¤§"),
    (1, 3, "æ–œç‡å¤ªå¤§")
]

ax2.scatter(X, y, alpha=0.6, color='blue', label='çœŸå®æ•°æ®')

# ç»˜åˆ¶æœ€ä½³æ‹Ÿåˆçº¿
ax2.plot(X, y_best, color='red', linewidth=3, label=f'æœ€ä½³æ‹Ÿåˆ (MSE={best_params[2]:.3f})')

# ç»˜åˆ¶ä¸å¥½çš„æ‹Ÿåˆçº¿
colors = ['green', 'orange', 'purple']
for i, (beta_0, beta_1, desc) in enumerate(bad_params):
    y_bad = beta_0 + beta_1 * X
    mse_bad = calculate_mse(X, y, beta_0, beta_1)
    ax2.plot(X, y_bad, color=colors[i], linewidth=2, linestyle='--', 
             label=f'{desc} (MSE={mse_bad:.3f})')

ax2.set_xlabel('ç‰¹å¾ X')
ax2.set_ylabel('ç›®æ ‡ y')
ax2.set_title('ä¸åŒå‚æ•°ä¸‹çš„æ‹Ÿåˆæ•ˆæœå¯¹æ¯”')
ax2.legend()
ax2.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# å¯è§†åŒ–3ï¼šè¯¯å·®åˆ†è§£
print("\nğŸ“Š å¯è§†åŒ–3: è¯¯å·®åˆ†è§£æ¼”ç¤º")

plt.figure(figsize=(12, 8))

# é€‰æ‹©å‡ ä¸ªæ•°æ®ç‚¹è¿›è¡Œè¯¦ç»†åˆ†æ
sample_indices = [0, 5, 10, 15]
sample_X = X[sample_indices]
sample_y = y[sample_indices]
sample_y_pred = best_params[0] + best_params[1] * sample_X

for i, (x, y_true, y_pred) in enumerate(zip(sample_X, sample_y, sample_y_pred)):
    plt.subplot(2, 2, i+1)
    
    # ç»˜åˆ¶æ‰€æœ‰æ•°æ®ç‚¹
    plt.scatter(X, y, alpha=0.3, color='lightblue')
    
    # é«˜äº®å½“å‰æ ·æœ¬
    plt.scatter(x, y_true, color='red', s=100, zorder=5)
    plt.scatter(x, y_pred, color='green', s=100, zorder=5)
    
    # ç»˜åˆ¶æ‹Ÿåˆçº¿
    plt.plot(X, y_best, color='blue', linewidth=2)
    
    # ç»˜åˆ¶è¯¯å·®çº¿
    plt.plot([x, x], [y_true, y_pred], color='red', linewidth=2, linestyle='--')
    
    # è®¡ç®—è¯¯å·®
    error = y_true - y_pred
    error_squared = error ** 2
    
    plt.title(f'æ ·æœ¬ {i+1}: è¯¯å·® = {error[0]:.3f}, å¹³æ–¹è¯¯å·® = {error_squared[0]:.3f}')
    plt.xlabel('ç‰¹å¾ X')
    plt.ylabel('ç›®æ ‡ y')
    plt.grid(True, alpha=0.3)

plt.tight_layout()
plt.show()

# æ•°å­¦è§£é‡Š
print("\nğŸ“š æ•°å­¦è§£é‡Š")
print("="*50)
print("1. MSE = (1/n) Ã— Î£(yáµ¢ - Å·áµ¢)Â²")
print("2. ç›®æ ‡ï¼šæ‰¾åˆ°å‚æ•° Î²â‚€, Î²â‚ï¼Œä½¿å¾— MSE æœ€å°")
print("3. å‡ ä½•æ„ä¹‰ï¼š")
print("   - æ¯ä¸ªç‚¹ (xáµ¢, yáµ¢) åˆ°æ‹Ÿåˆçº¿çš„å‚ç›´è·ç¦»")
print("   - å¹³æ–¹åæ±‚å’Œï¼Œå†æ±‚å¹³å‡")
print("   - æ‰¾åˆ°ä½¿è¿™ä¸ªæ€»è·ç¦»æœ€å°çš„ç›´çº¿")

print("\n4. ä¸ºä»€ä¹ˆç”¨å¹³æ–¹ï¼Ÿ")
print("   - é¿å…æ­£è´Ÿè¯¯å·®æŠµæ¶ˆ")
print("   - å¤§è¯¯å·®è¢«æ›´ä¸¥é‡æƒ©ç½š")
print("   - æ•°å­¦æ€§è´¨å¥½ï¼ˆå‡¸å‡½æ•°ï¼‰")

print("\n5. æœ€å°åŒ–è¿‡ç¨‹ï¼š")
print("   - å¯¹ Î²â‚€ æ±‚åå¯¼ï¼Œä»¤å…¶ç­‰äº0")
print("   - å¯¹ Î²â‚ æ±‚åå¯¼ï¼Œä»¤å…¶ç­‰äº0")
print("   - è§£æ–¹ç¨‹ç»„å¾—åˆ°æœ€ä½³å‚æ•°")

# å®é™…è®¡ç®—æ¼”ç¤º
print("\nğŸ”¢ å®é™…è®¡ç®—æ¼”ç¤º")
print("="*50)

# ä½¿ç”¨sklearnéªŒè¯
model = LinearRegression()
model.fit(X, y)
sklearn_beta_0 = model.intercept_[0]
sklearn_beta_1 = model.coef_[0][0]
sklearn_mse = calculate_mse(X, y, sklearn_beta_0, sklearn_beta_1)

print(f"æˆ‘ä»¬çš„æœ€ä½³å‚æ•°: Î²â‚€ = {best_params[0]:.4f}, Î²â‚ = {best_params[1]:.4f}")
print(f"sklearnçš„å‚æ•°:   Î²â‚€ = {sklearn_beta_0:.4f}, Î²â‚ = {sklearn_beta_1:.4f}")
print(f"æˆ‘ä»¬çš„MSE: {best_params[2]:.4f}")
print(f"sklearnçš„MSE: {sklearn_mse:.4f}")
print(f"å·®å¼‚: {abs(best_params[2] - sklearn_mse):.6f}")

print("\nâœ… ç»“è®ºï¼šæœ€å°åŒ–MSEå°±æ˜¯æ‰¾åˆ°æœ€æ¥è¿‘æ‰€æœ‰æ•°æ®ç‚¹çš„ç›´çº¿ï¼") 